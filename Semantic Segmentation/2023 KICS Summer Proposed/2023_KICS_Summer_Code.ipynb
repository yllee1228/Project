{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d82b34ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Owner\\anaconda3\\envs\\TensorFlow\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import keract\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "# import albumentations as A\n",
    "from IPython.display import SVG\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os, re, sys, random, shutil, cv2, time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, Nadam\n",
    "from tensorflow.keras import applications, optimizers\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications import ResNet152V2\n",
    "from tensorflow.keras.utils import model_to_dot, plot_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger, LearningRateScheduler\n",
    "from tensorflow.keras.layers import Convolution2D, BatchNormalization, ReLU,LeakyReLU,Add, Activation, Conv2DTranspose, MaxPool2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, AveragePooling2D, UpSampling2D, Input, Dropout, ZeroPadding2D, Concatenate\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d8fe93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b37f7c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e: \n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5125f2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = \"./datasets/input/train_image2/\"\n",
    "train_masks = \"./datasets/input/train_mask2/\"\n",
    "val_images = \"./datasets/input/val_image2/\"\n",
    "val_masks = \"./datasets/input/val_mask2/\"\n",
    "test_images = \"./datasets/input/test_image2/\"\n",
    "test_masks = \"./datasets/input/test_mask2/\"\n",
    "\n",
    "num_classes = 6\n",
    "input_size = (256, 256, 3)\n",
    "image_size = (256, 256)\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4dfcf98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>r</th>\n",
       "      <th>g</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>building</td>\n",
       "      <td>60</td>\n",
       "      <td>16</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>land</td>\n",
       "      <td>132</td>\n",
       "      <td>41</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>road</td>\n",
       "      <td>110</td>\n",
       "      <td>193</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vegetation</td>\n",
       "      <td>254</td>\n",
       "      <td>221</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>water</td>\n",
       "      <td>226</td>\n",
       "      <td>169</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>unlabeled</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name    r    g    b\n",
       "0    building   60   16  152\n",
       "1        land  132   41  246\n",
       "2        road  110  193  228\n",
       "3  vegetation  254  221   58\n",
       "4       water  226  169   41\n",
       "5   unlabeled  155  155  155"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict_df = pd.read_csv('./datasets/input/class_dict.csv', index_col=False, skipinitialspace=True)\n",
    "class_dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dada4924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(60, 16, 152),\n",
       "  (132, 41, 246),\n",
       "  (110, 193, 228),\n",
       "  (254, 221, 58),\n",
       "  (226, 169, 41),\n",
       "  (155, 155, 155)],\n",
       " ['building', 'land', 'road', 'vegetation', 'water', 'unlabeled'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names= list(class_dict_df.name)\n",
    "label_codes = []\n",
    "r= np.asarray(class_dict_df.r)\n",
    "g= np.asarray(class_dict_df.g)\n",
    "b= np.asarray(class_dict_df.b)\n",
    "\n",
    "for i in range(len(class_dict_df)):\n",
    "    label_codes.append(tuple([r[i], g[i], b[i]]))\n",
    "    \n",
    "label_codes, label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aea146fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "code2id = {v:k for k,v in enumerate(label_codes)}\n",
    "id2code = {k:v for k,v in enumerate(label_codes)}\n",
    "\n",
    "name2id = {v:k for k,v in enumerate(label_names)}\n",
    "id2name = {k:v for k,v in enumerate(label_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e33e8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: (60, 16, 152),\n",
       "  1: (132, 41, 246),\n",
       "  2: (110, 193, 228),\n",
       "  3: (254, 221, 58),\n",
       "  4: (226, 169, 41),\n",
       "  5: (155, 155, 155)},\n",
       " {0: 'building',\n",
       "  1: 'land',\n",
       "  2: 'road',\n",
       "  3: 'vegetation',\n",
       "  4: 'water',\n",
       "  5: 'unlabeled'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2code, id2name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b13139b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_onehot(rgb_image, colormap = id2code):\n",
    "    '''Function to one hot encode RGB mask labels\n",
    "        Inputs: \n",
    "            rgb_image - image matrix (eg. 256 x 256 x 3 dimension numpy ndarray)\n",
    "            colormap - dictionary of color to label id\n",
    "        Output: One hot encoded image of dimensions (height x width x num_classes) where num_classes = len(colormap)\n",
    "    '''\n",
    "    num_classes = len(colormap)\n",
    "    shape = rgb_image.shape[:2]+(num_classes,)\n",
    "    encoded_image = np.zeros(shape, dtype=np.int8)\n",
    "    for i, cls in enumerate(colormap):\n",
    "        encoded_image[:,:,i] = np.all(rgb_image.reshape((-1,3)) == colormap[i], axis=1).reshape(shape[:2])\n",
    "    return encoded_image\n",
    "\n",
    "\n",
    "def onehot_to_rgb(onehot, colormap = id2code):\n",
    "    '''Function to decode encoded mask labels\n",
    "        Inputs: \n",
    "            onehot - one hot encoded image matrix (height x width x num_classes)\n",
    "            colormap - dictionary of color to label id\n",
    "        Output: Decoded RGB image (height x width x 3) \n",
    "    '''\n",
    "    single_layer = np.argmax(onehot, axis=-1)\n",
    "    output = np.zeros(onehot.shape[:2] + (3,))\n",
    "    for k in colormap.keys():\n",
    "        output[single_layer==k] = colormap[k]\n",
    "    return np.uint8(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eec7359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing only frame images, since masks contain label info\n",
    "data_gen_args = dict(rescale=1./255)\n",
    "mask_gen_args = dict()\n",
    "\n",
    "train_frames_datagen = ImageDataGenerator(**data_gen_args)\n",
    "train_masks_datagen = ImageDataGenerator(**mask_gen_args)\n",
    "val_frames_datagen = ImageDataGenerator(**data_gen_args)\n",
    "val_masks_datagen = ImageDataGenerator(**mask_gen_args)\n",
    "\n",
    "# Seed defined for aligning images and their masks\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cd61841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainAugmentGenerator(train_images_dir, train_masks_dir, seed = 1, batch_size = batch_size, target_size = image_size):\n",
    "    '''Train Image data generator\n",
    "        Inputs: \n",
    "            seed - seed provided to the flow_from_directory function to ensure aligned data flow\n",
    "            batch_size - number of images to import at a time\n",
    "            train_images_dir - train images directory\n",
    "            train_masks_dir - train masks directory\n",
    "            target_size - tuple of integers (height, width)\n",
    "            \n",
    "        Output: Decoded RGB image (height x width x 3) \n",
    "    '''\n",
    "    train_image_generator = train_frames_datagen.flow_from_directory(\n",
    "    train_images_dir,\n",
    "    batch_size = batch_size,\n",
    "    color_mode = 'rgb',\n",
    "    #color_mode = 'grayscale', #흑백사진 일 경우\n",
    "    seed = seed, \n",
    "    target_size = target_size)\n",
    "\n",
    "    train_mask_generator = train_masks_datagen.flow_from_directory(\n",
    "    train_masks_dir,\n",
    "    batch_size = batch_size, \n",
    "    seed = seed, \n",
    "    target_size = target_size)\n",
    "\n",
    "    while True:\n",
    "        X1i = train_image_generator.next()\n",
    "        X2i = train_mask_generator.next()\n",
    "        \n",
    "        #One hot encoding RGB images\n",
    "        mask_encoded = [rgb_to_onehot(X2i[0][x,:,:,:], id2code) for x in range(X2i[0].shape[0])]\n",
    "          \n",
    "        yield X1i[0], np.asarray(mask_encoded)\n",
    "\n",
    "def ValAugmentGenerator(val_images_dir, val_masks_dir, seed = 1, batch_size = batch_size, target_size = image_size):\n",
    "    '''Validation Image data generator\n",
    "        Inputs: \n",
    "            seed - seed provided to the flow_from_directory function to ensure aligned data flow\n",
    "            batch_size - number of images to import at a time\n",
    "            val_images_dir - validation images directory\n",
    "            val_masks_dir - validation masks directory\n",
    "            target_size - tuple of integers (height, width)\n",
    "            \n",
    "        Output: Decoded RGB image (height x width x 3) \n",
    "    '''\n",
    "    val_image_generator = val_frames_datagen.flow_from_directory(\n",
    "    val_images_dir,\n",
    "    batch_size = batch_size,\n",
    "    color_mode = 'rgb',\n",
    "    #color_mode = 'grayscale', #흑백사진 일 경우\n",
    "    seed = seed, \n",
    "    target_size = target_size)\n",
    "\n",
    "\n",
    "    val_mask_generator = val_masks_datagen.flow_from_directory(\n",
    "    val_masks_dir,\n",
    "    batch_size = batch_size, \n",
    "    seed = seed, \n",
    "    target_size = target_size)\n",
    "\n",
    "\n",
    "    while True:\n",
    "        X1i = val_image_generator.next()\n",
    "        X2i = val_mask_generator.next()\n",
    "        \n",
    "        #One hot encoding RGB images\n",
    "        mask_encoded = [rgb_to_onehot(X2i[0][x,:,:,:], id2code) for x in range(X2i[0].shape[0])]\n",
    "        \n",
    "#         print(f'mask_encoded: {np.asarray(mask_encoded)}')\n",
    "        \n",
    "        yield X1i[0], np.asarray(mask_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14a5d712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch:  18.0\n",
      "validation_steps:  22.0\n"
     ]
    }
   ],
   "source": [
    "num_train_samples = len(np.sort(os.listdir(train_images + \"images/\")))\n",
    "num_val_samples = len(np.sort(os.listdir(val_images + \"images/\")))\n",
    "steps_per_epoch = np.ceil(float(num_train_samples) / float(batch_size)/5)\n",
    "print('steps_per_epoch: ', steps_per_epoch)\n",
    "validation_steps = np.ceil(float(4 * num_val_samples) / float(batch_size)/5)\n",
    "print('validation_steps: ', validation_steps)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "19d07fb8",
   "metadata": {},
   "source": [
    "input_shape = (256, 256, 3)\n",
    "inputs = Input(input_shape)\n",
    "encoder = InceptionResNetV2(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb38987e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_link_block(orginal_inputs, add_inputs1, add_inputs2, num_filters):\n",
    "    original_inputs = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(orginal_inputs)\n",
    "    add_inputs2 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(add_inputs2)\n",
    "    concat = Concatenate()([original_inputs, add_inputs1, add_inputs2])\n",
    "    x = Convolution2D(num_filters, 3, padding=\"same\")(concat)\n",
    "    return x\n",
    "\n",
    "def build_model(input_shape):\n",
    "    \"\"\" Input \"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "    \"\"\" Pre-trained NetV2 Model \"\"\"\n",
    "    encoder = InceptionResNetV2(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
    "    \n",
    "    \"\"\" Encoder \"\"\"\n",
    "    s1 = encoder.get_layer(\"input_1\").output           ## (256 x 256)\n",
    "\n",
    "    s2 = encoder.get_layer(\"activation_2\").output      ## (125 x 125)\n",
    "    s2 = ZeroPadding2D(((2, 1),(2, 1)))(s2)            ## (128 x 128)\n",
    "\n",
    "    s3 = encoder.get_layer(\"activation_4\").output      ## (60 x 60)\n",
    "    s3 = ZeroPadding2D((2, 2))(s3)                     ## (64 x 64)\n",
    "\n",
    "    s4 = encoder.get_layer(\"activation_74\").output      ## (29 x 29)\n",
    "    s4 = ZeroPadding2D(((2, 1),(2, 1)))(s4)             ## (32 x 32)\n",
    "\n",
    "    \"\"\" Bridge \"\"\"\n",
    "    b1 = encoder.get_layer(\"activation_161\").output     ## (14 x 14)\n",
    "    b1 = ZeroPadding2D((1, 1))(b1)                      ## (16 x 16)\n",
    "    \n",
    "    \"\"\" Decoder \"\"\"\n",
    "    x = multi_link_block(b1, s4, s3, 128)\n",
    "    x = multi_link_block(x, s3, s2, 64)\n",
    "    x = multi_link_block(x, s2, s1, 32)\n",
    "    \n",
    "    \"\"\" Connected \"\"\"\n",
    "    x = Conv2DTranspose(16, (2, 2), strides=2, padding=\"same\")(x)\n",
    "    s1 = Convolution2D(16, 3, padding=\"same\")(s1)\n",
    "    \n",
    "    outputs = Concatenate()([x, s1])\n",
    "    \n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6689297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_conv_module(input_shape):\n",
    "    inputs, X = build_model(input_shape)\n",
    "    X = Convolution2D(filters=3, kernel_size=3, padding='same')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    # dropout = Dropout(0.3)(X)\n",
    "    outputs = Convolution2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(X)\n",
    "    \n",
    "    model = Model(inputs, outputs, name=\"InceptionResNetV2\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1de4c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    # Flatten\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "# ship detection = class 2개일 때 클래스 불균형 확인차 iou 2개(metrics=[iou0, iou1, dice_coef, \"accuracy\"]) 설정\n",
    "# 다중 클래스일 경우, mean iou 사용\n",
    "\n",
    "def mean_iou(y_true, y_pred, num_classes = 6):\n",
    "    \"\"\"\n",
    "    Calculate the mean IoU across all classes.\n",
    "    Args:\n",
    "        y_true: the expected y values as a one-hot encoded tensor\n",
    "        y_pred: the predicted y values as a one-hot or softmax tensor\n",
    "        num_classes: total number of classes\n",
    "    Returns:\n",
    "        mean IoU across all classes\n",
    "    \"\"\"\n",
    "    ious = []\n",
    "    y_true = K.argmax(y_true, axis=-1)  # 라벨 인코딩으로 변환\n",
    "    y_pred = K.argmax(y_pred, axis=-1)  # 예측값 인코딩으로 변환\n",
    "\n",
    "    for label in range(num_classes):\n",
    "        y_true_label = K.cast(K.equal(y_true, label), K.floatx())\n",
    "        y_pred_label = K.cast(K.equal(y_pred, label), K.floatx())\n",
    "        \n",
    "        # Intersection과 Union 계산\n",
    "        intersection = K.sum(y_true_label * y_pred_label)\n",
    "        union = K.sum(y_true_label) + K.sum(y_pred_label) - intersection\n",
    "        \n",
    "        # IoU 계산 (divide by zero 방지)\n",
    "        iou = K.switch(K.equal(union, 0), 1.0, intersection / union)\n",
    "        ious.append(iou)\n",
    "    \n",
    "    # 모든 클래스의 IoU 평균\n",
    "    mean_iou = K.mean(K.stack(ious), axis=0)\n",
    "    \n",
    "    return mean_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "595c9750",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = last_conv_module(input_shape = (256, 256, 3))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "04fb73d2",
   "metadata": {},
   "source": [
    "# 비교 실험 Semantic Segmentation\n",
    "import segmentation_models as sm\n",
    "\n",
    "model = sm.Unet('inceptionresnetv2', input_shape=(256, 256, 3), classes=6, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bcdc9728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_209 (Conv2D)            (None, 128, 128, 32  864         ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_204 (Batch  (None, 128, 128, 32  96         ['conv2d_209[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_203 (Activation)    (None, 128, 128, 32  0           ['batch_normalization_204[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_210 (Conv2D)            (None, 128, 128, 32  9216        ['activation_203[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_205 (Batch  (None, 128, 128, 32  96         ['conv2d_210[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_204 (Activation)    (None, 128, 128, 32  0           ['batch_normalization_205[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_211 (Conv2D)            (None, 128, 128, 64  18432       ['activation_204[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_206 (Batch  (None, 128, 128, 64  192        ['conv2d_211[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_205 (Activation)    (None, 128, 128, 64  0           ['batch_normalization_206[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 64, 64, 64)  0           ['activation_205[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_212 (Conv2D)            (None, 64, 64, 80)   5120        ['max_pooling2d_7[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_207 (Batch  (None, 64, 64, 80)  240         ['conv2d_212[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_206 (Activation)    (None, 64, 64, 80)   0           ['batch_normalization_207[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_213 (Conv2D)            (None, 64, 64, 192)  138240      ['activation_206[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_208 (Batch  (None, 64, 64, 192)  576        ['conv2d_213[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_207 (Activation)    (None, 64, 64, 192)  0           ['batch_normalization_208[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 32, 32, 192)  0          ['activation_207[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_217 (Conv2D)            (None, 32, 32, 64)   12288       ['max_pooling2d_8[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_212 (Batch  (None, 32, 32, 64)  192         ['conv2d_217[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_211 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_212[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_215 (Conv2D)            (None, 32, 32, 48)   9216        ['max_pooling2d_8[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_218 (Conv2D)            (None, 32, 32, 96)   55296       ['activation_211[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_210 (Batch  (None, 32, 32, 48)  144         ['conv2d_215[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_213 (Batch  (None, 32, 32, 96)  288         ['conv2d_218[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_209 (Activation)    (None, 32, 32, 48)   0           ['batch_normalization_210[0][0]']\n",
      "                                                                                                  \n",
      " activation_212 (Activation)    (None, 32, 32, 96)   0           ['batch_normalization_213[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 32, 32, 192)  0          ['max_pooling2d_8[0][0]']        \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_214 (Conv2D)            (None, 32, 32, 96)   18432       ['max_pooling2d_8[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_216 (Conv2D)            (None, 32, 32, 64)   76800       ['activation_209[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_219 (Conv2D)            (None, 32, 32, 96)   82944       ['activation_212[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_220 (Conv2D)            (None, 32, 32, 64)   12288       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_209 (Batch  (None, 32, 32, 96)  288         ['conv2d_214[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_211 (Batch  (None, 32, 32, 64)  192         ['conv2d_216[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_214 (Batch  (None, 32, 32, 96)  288         ['conv2d_219[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_215 (Batch  (None, 32, 32, 64)  192         ['conv2d_220[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_208 (Activation)    (None, 32, 32, 96)   0           ['batch_normalization_209[0][0]']\n",
      "                                                                                                  \n",
      " activation_210 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_211[0][0]']\n",
      "                                                                                                  \n",
      " activation_213 (Activation)    (None, 32, 32, 96)   0           ['batch_normalization_214[0][0]']\n",
      "                                                                                                  \n",
      " activation_214 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_215[0][0]']\n",
      "                                                                                                  \n",
      " mixed_5b (Concatenate)         (None, 32, 32, 320)  0           ['activation_208[0][0]',         \n",
      "                                                                  'activation_210[0][0]',         \n",
      "                                                                  'activation_213[0][0]',         \n",
      "                                                                  'activation_214[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_224 (Conv2D)            (None, 32, 32, 32)   10240       ['mixed_5b[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_219 (Batch  (None, 32, 32, 32)  96          ['conv2d_224[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_218 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_219[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_222 (Conv2D)            (None, 32, 32, 32)   10240       ['mixed_5b[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_225 (Conv2D)            (None, 32, 32, 48)   13824       ['activation_218[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_217 (Batch  (None, 32, 32, 32)  96          ['conv2d_222[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_220 (Batch  (None, 32, 32, 48)  144         ['conv2d_225[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_216 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_217[0][0]']\n",
      "                                                                                                  \n",
      " activation_219 (Activation)    (None, 32, 32, 48)   0           ['batch_normalization_220[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_221 (Conv2D)            (None, 32, 32, 32)   10240       ['mixed_5b[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_223 (Conv2D)            (None, 32, 32, 32)   9216        ['activation_216[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_226 (Conv2D)            (None, 32, 32, 64)   27648       ['activation_219[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_216 (Batch  (None, 32, 32, 32)  96          ['conv2d_221[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_218 (Batch  (None, 32, 32, 32)  96          ['conv2d_223[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_221 (Batch  (None, 32, 32, 64)  192         ['conv2d_226[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_215 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_216[0][0]']\n",
      "                                                                                                  \n",
      " activation_217 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_218[0][0]']\n",
      "                                                                                                  \n",
      " activation_220 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_221[0][0]']\n",
      "                                                                                                  \n",
      " block35_1_mixed (Concatenate)  (None, 32, 32, 128)  0           ['activation_215[0][0]',         \n",
      "                                                                  'activation_217[0][0]',         \n",
      "                                                                  'activation_220[0][0]']         \n",
      "                                                                                                  \n",
      " block35_1_conv (Conv2D)        (None, 32, 32, 320)  41280       ['block35_1_mixed[0][0]']        \n",
      "                                                                                                  \n",
      " block35_1 (Lambda)             (None, 32, 32, 320)  0           ['mixed_5b[0][0]',               \n",
      "                                                                  'block35_1_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block35_1_ac (Activation)      (None, 32, 32, 320)  0           ['block35_1[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_230 (Conv2D)            (None, 32, 32, 32)   10240       ['block35_1_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_225 (Batch  (None, 32, 32, 32)  96          ['conv2d_230[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " activation_224 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_225[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_228 (Conv2D)            (None, 32, 32, 32)   10240       ['block35_1_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_231 (Conv2D)            (None, 32, 32, 48)   13824       ['activation_224[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_223 (Batch  (None, 32, 32, 32)  96          ['conv2d_228[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_226 (Batch  (None, 32, 32, 48)  144         ['conv2d_231[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_222 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_223[0][0]']\n",
      "                                                                                                  \n",
      " activation_225 (Activation)    (None, 32, 32, 48)   0           ['batch_normalization_226[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_227 (Conv2D)            (None, 32, 32, 32)   10240       ['block35_1_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_229 (Conv2D)            (None, 32, 32, 32)   9216        ['activation_222[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_232 (Conv2D)            (None, 32, 32, 64)   27648       ['activation_225[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_222 (Batch  (None, 32, 32, 32)  96          ['conv2d_227[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_224 (Batch  (None, 32, 32, 32)  96          ['conv2d_229[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_227 (Batch  (None, 32, 32, 64)  192         ['conv2d_232[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_221 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_222[0][0]']\n",
      "                                                                                                  \n",
      " activation_223 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_224[0][0]']\n",
      "                                                                                                  \n",
      " activation_226 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_227[0][0]']\n",
      "                                                                                                  \n",
      " block35_2_mixed (Concatenate)  (None, 32, 32, 128)  0           ['activation_221[0][0]',         \n",
      "                                                                  'activation_223[0][0]',         \n",
      "                                                                  'activation_226[0][0]']         \n",
      "                                                                                                  \n",
      " block35_2_conv (Conv2D)        (None, 32, 32, 320)  41280       ['block35_2_mixed[0][0]']        \n",
      "                                                                                                  \n",
      " block35_2 (Lambda)             (None, 32, 32, 320)  0           ['block35_1_ac[0][0]',           \n",
      "                                                                  'block35_2_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block35_2_ac (Activation)      (None, 32, 32, 320)  0           ['block35_2[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_236 (Conv2D)            (None, 32, 32, 32)   10240       ['block35_2_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_231 (Batch  (None, 32, 32, 32)  96          ['conv2d_236[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_230 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_231[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_234 (Conv2D)            (None, 32, 32, 32)   10240       ['block35_2_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_237 (Conv2D)            (None, 32, 32, 48)   13824       ['activation_230[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_229 (Batch  (None, 32, 32, 32)  96          ['conv2d_234[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_232 (Batch  (None, 32, 32, 48)  144         ['conv2d_237[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_228 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_229[0][0]']\n",
      "                                                                                                  \n",
      " activation_231 (Activation)    (None, 32, 32, 48)   0           ['batch_normalization_232[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_233 (Conv2D)            (None, 32, 32, 32)   10240       ['block35_2_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_235 (Conv2D)            (None, 32, 32, 32)   9216        ['activation_228[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_238 (Conv2D)            (None, 32, 32, 64)   27648       ['activation_231[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_228 (Batch  (None, 32, 32, 32)  96          ['conv2d_233[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_230 (Batch  (None, 32, 32, 32)  96          ['conv2d_235[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_233 (Batch  (None, 32, 32, 64)  192         ['conv2d_238[0][0]']             \n",
      " Normalization)                                                                                   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " activation_227 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_228[0][0]']\n",
      "                                                                                                  \n",
      " activation_229 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_230[0][0]']\n",
      "                                                                                                  \n",
      " activation_232 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_233[0][0]']\n",
      "                                                                                                  \n",
      " block35_3_mixed (Concatenate)  (None, 32, 32, 128)  0           ['activation_227[0][0]',         \n",
      "                                                                  'activation_229[0][0]',         \n",
      "                                                                  'activation_232[0][0]']         \n",
      "                                                                                                  \n",
      " block35_3_conv (Conv2D)        (None, 32, 32, 320)  41280       ['block35_3_mixed[0][0]']        \n",
      "                                                                                                  \n",
      " block35_3 (Lambda)             (None, 32, 32, 320)  0           ['block35_2_ac[0][0]',           \n",
      "                                                                  'block35_3_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block35_3_ac (Activation)      (None, 32, 32, 320)  0           ['block35_3[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_242 (Conv2D)            (None, 32, 32, 32)   10240       ['block35_3_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_237 (Batch  (None, 32, 32, 32)  96          ['conv2d_242[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_236 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_237[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_240 (Conv2D)            (None, 32, 32, 32)   10240       ['block35_3_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_243 (Conv2D)            (None, 32, 32, 48)   13824       ['activation_236[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_235 (Batch  (None, 32, 32, 32)  96          ['conv2d_240[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_238 (Batch  (None, 32, 32, 48)  144         ['conv2d_243[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_234 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_235[0][0]']\n",
      "                                                                                                  \n",
      " activation_237 (Activation)    (None, 32, 32, 48)   0           ['batch_normalization_238[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_239 (Conv2D)            (None, 32, 32, 32)   10240       ['block35_3_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_241 (Conv2D)            (None, 32, 32, 32)   9216        ['activation_234[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_244 (Conv2D)            (None, 32, 32, 64)   27648       ['activation_237[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_234 (Batch  (None, 32, 32, 32)  96          ['conv2d_239[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_236 (Batch  (None, 32, 32, 32)  96          ['conv2d_241[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_239 (Batch  (None, 32, 32, 64)  192         ['conv2d_244[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_233 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_234[0][0]']\n",
      "                                                                                                  \n",
      " activation_235 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_236[0][0]']\n",
      "                                                                                                  \n",
      " activation_238 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_239[0][0]']\n",
      "                                                                                                  \n",
      " block35_4_mixed (Concatenate)  (None, 32, 32, 128)  0           ['activation_233[0][0]',         \n",
      "                                                                  'activation_235[0][0]',         \n",
      "                                                                  'activation_238[0][0]']         \n",
      "                                                                                                  \n",
      " block35_4_conv (Conv2D)        (None, 32, 32, 320)  41280       ['block35_4_mixed[0][0]']        \n",
      "                                                                                                  \n",
      " block35_4 (Lambda)             (None, 32, 32, 320)  0           ['block35_3_ac[0][0]',           \n",
      "                                                                  'block35_4_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block35_4_ac (Activation)      (None, 32, 32, 320)  0           ['block35_4[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_248 (Conv2D)            (None, 32, 32, 32)   10240       ['block35_4_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_243 (Batch  (None, 32, 32, 32)  96          ['conv2d_248[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_242 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_243[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_246 (Conv2D)            (None, 32, 32, 32)   10240       ['block35_4_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_249 (Conv2D)            (None, 32, 32, 48)   13824       ['activation_242[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_241 (Batch  (None, 32, 32, 32)  96          ['conv2d_246[0][0]']             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_244 (Batch  (None, 32, 32, 48)  144         ['conv2d_249[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_240 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_241[0][0]']\n",
      "                                                                                                  \n",
      " activation_243 (Activation)    (None, 32, 32, 48)   0           ['batch_normalization_244[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_245 (Conv2D)            (None, 32, 32, 32)   10240       ['block35_4_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_247 (Conv2D)            (None, 32, 32, 32)   9216        ['activation_240[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_250 (Conv2D)            (None, 32, 32, 64)   27648       ['activation_243[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_240 (Batch  (None, 32, 32, 32)  96          ['conv2d_245[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_242 (Batch  (None, 32, 32, 32)  96          ['conv2d_247[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_245 (Batch  (None, 32, 32, 64)  192         ['conv2d_250[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_239 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_240[0][0]']\n",
      "                                                                                                  \n",
      " activation_241 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_242[0][0]']\n",
      "                                                                                                  \n",
      " activation_244 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_245[0][0]']\n",
      "                                                                                                  \n",
      " block35_5_mixed (Concatenate)  (None, 32, 32, 128)  0           ['activation_239[0][0]',         \n",
      "                                                                  'activation_241[0][0]',         \n",
      "                                                                  'activation_244[0][0]']         \n",
      "                                                                                                  \n",
      " block35_5_conv (Conv2D)        (None, 32, 32, 320)  41280       ['block35_5_mixed[0][0]']        \n",
      "                                                                                                  \n",
      " block35_5 (Lambda)             (None, 32, 32, 320)  0           ['block35_4_ac[0][0]',           \n",
      "                                                                  'block35_5_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block35_5_ac (Activation)      (None, 32, 32, 320)  0           ['block35_5[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_254 (Conv2D)            (None, 32, 32, 32)   10240       ['block35_5_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_249 (Batch  (None, 32, 32, 32)  96          ['conv2d_254[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_248 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_249[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_252 (Conv2D)            (None, 32, 32, 32)   10240       ['block35_5_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_255 (Conv2D)            (None, 32, 32, 48)   13824       ['activation_248[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_247 (Batch  (None, 32, 32, 32)  96          ['conv2d_252[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_250 (Batch  (None, 32, 32, 48)  144         ['conv2d_255[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_246 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_247[0][0]']\n",
      "                                                                                                  \n",
      " activation_249 (Activation)    (None, 32, 32, 48)   0           ['batch_normalization_250[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_251 (Conv2D)            (None, 32, 32, 32)   10240       ['block35_5_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_253 (Conv2D)            (None, 32, 32, 32)   9216        ['activation_246[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_256 (Conv2D)            (None, 32, 32, 64)   27648       ['activation_249[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_246 (Batch  (None, 32, 32, 32)  96          ['conv2d_251[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_248 (Batch  (None, 32, 32, 32)  96          ['conv2d_253[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_251 (Batch  (None, 32, 32, 64)  192         ['conv2d_256[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_245 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_246[0][0]']\n",
      "                                                                                                  \n",
      " activation_247 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_248[0][0]']\n",
      "                                                                                                  \n",
      " activation_250 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_251[0][0]']\n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block35_6_mixed (Concatenate)  (None, 32, 32, 128)  0           ['activation_245[0][0]',         \n",
      "                                                                  'activation_247[0][0]',         \n",
      "                                                                  'activation_250[0][0]']         \n",
      "                                                                                                  \n",
      " block35_6_conv (Conv2D)        (None, 32, 32, 320)  41280       ['block35_6_mixed[0][0]']        \n",
      "                                                                                                  \n",
      " block35_6 (Lambda)             (None, 32, 32, 320)  0           ['block35_5_ac[0][0]',           \n",
      "                                                                  'block35_6_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block35_6_ac (Activation)      (None, 32, 32, 320)  0           ['block35_6[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_260 (Conv2D)            (None, 32, 32, 32)   10240       ['block35_6_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_255 (Batch  (None, 32, 32, 32)  96          ['conv2d_260[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_254 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_255[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_258 (Conv2D)            (None, 32, 32, 32)   10240       ['block35_6_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_261 (Conv2D)            (None, 32, 32, 48)   13824       ['activation_254[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_253 (Batch  (None, 32, 32, 32)  96          ['conv2d_258[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_256 (Batch  (None, 32, 32, 48)  144         ['conv2d_261[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_252 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_253[0][0]']\n",
      "                                                                                                  \n",
      " activation_255 (Activation)    (None, 32, 32, 48)   0           ['batch_normalization_256[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_257 (Conv2D)            (None, 32, 32, 32)   10240       ['block35_6_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_259 (Conv2D)            (None, 32, 32, 32)   9216        ['activation_252[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_262 (Conv2D)            (None, 32, 32, 64)   27648       ['activation_255[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_252 (Batch  (None, 32, 32, 32)  96          ['conv2d_257[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_254 (Batch  (None, 32, 32, 32)  96          ['conv2d_259[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_257 (Batch  (None, 32, 32, 64)  192         ['conv2d_262[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_251 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_252[0][0]']\n",
      "                                                                                                  \n",
      " activation_253 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_254[0][0]']\n",
      "                                                                                                  \n",
      " activation_256 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_257[0][0]']\n",
      "                                                                                                  \n",
      " block35_7_mixed (Concatenate)  (None, 32, 32, 128)  0           ['activation_251[0][0]',         \n",
      "                                                                  'activation_253[0][0]',         \n",
      "                                                                  'activation_256[0][0]']         \n",
      "                                                                                                  \n",
      " block35_7_conv (Conv2D)        (None, 32, 32, 320)  41280       ['block35_7_mixed[0][0]']        \n",
      "                                                                                                  \n",
      " block35_7 (Lambda)             (None, 32, 32, 320)  0           ['block35_6_ac[0][0]',           \n",
      "                                                                  'block35_7_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block35_7_ac (Activation)      (None, 32, 32, 320)  0           ['block35_7[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_266 (Conv2D)            (None, 32, 32, 32)   10240       ['block35_7_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_261 (Batch  (None, 32, 32, 32)  96          ['conv2d_266[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_260 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_261[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_264 (Conv2D)            (None, 32, 32, 32)   10240       ['block35_7_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_267 (Conv2D)            (None, 32, 32, 48)   13824       ['activation_260[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_259 (Batch  (None, 32, 32, 32)  96          ['conv2d_264[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_262 (Batch  (None, 32, 32, 48)  144         ['conv2d_267[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_258 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_259[0][0]']\n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " activation_261 (Activation)    (None, 32, 32, 48)   0           ['batch_normalization_262[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_263 (Conv2D)            (None, 32, 32, 32)   10240       ['block35_7_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_265 (Conv2D)            (None, 32, 32, 32)   9216        ['activation_258[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_268 (Conv2D)            (None, 32, 32, 64)   27648       ['activation_261[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_258 (Batch  (None, 32, 32, 32)  96          ['conv2d_263[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_260 (Batch  (None, 32, 32, 32)  96          ['conv2d_265[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_263 (Batch  (None, 32, 32, 64)  192         ['conv2d_268[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_257 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_258[0][0]']\n",
      "                                                                                                  \n",
      " activation_259 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_260[0][0]']\n",
      "                                                                                                  \n",
      " activation_262 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_263[0][0]']\n",
      "                                                                                                  \n",
      " block35_8_mixed (Concatenate)  (None, 32, 32, 128)  0           ['activation_257[0][0]',         \n",
      "                                                                  'activation_259[0][0]',         \n",
      "                                                                  'activation_262[0][0]']         \n",
      "                                                                                                  \n",
      " block35_8_conv (Conv2D)        (None, 32, 32, 320)  41280       ['block35_8_mixed[0][0]']        \n",
      "                                                                                                  \n",
      " block35_8 (Lambda)             (None, 32, 32, 320)  0           ['block35_7_ac[0][0]',           \n",
      "                                                                  'block35_8_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block35_8_ac (Activation)      (None, 32, 32, 320)  0           ['block35_8[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_272 (Conv2D)            (None, 32, 32, 32)   10240       ['block35_8_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_267 (Batch  (None, 32, 32, 32)  96          ['conv2d_272[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_266 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_267[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_270 (Conv2D)            (None, 32, 32, 32)   10240       ['block35_8_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_273 (Conv2D)            (None, 32, 32, 48)   13824       ['activation_266[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_265 (Batch  (None, 32, 32, 32)  96          ['conv2d_270[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_268 (Batch  (None, 32, 32, 48)  144         ['conv2d_273[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_264 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_265[0][0]']\n",
      "                                                                                                  \n",
      " activation_267 (Activation)    (None, 32, 32, 48)   0           ['batch_normalization_268[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_269 (Conv2D)            (None, 32, 32, 32)   10240       ['block35_8_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_271 (Conv2D)            (None, 32, 32, 32)   9216        ['activation_264[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_274 (Conv2D)            (None, 32, 32, 64)   27648       ['activation_267[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_264 (Batch  (None, 32, 32, 32)  96          ['conv2d_269[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_266 (Batch  (None, 32, 32, 32)  96          ['conv2d_271[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_269 (Batch  (None, 32, 32, 64)  192         ['conv2d_274[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_263 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_264[0][0]']\n",
      "                                                                                                  \n",
      " activation_265 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_266[0][0]']\n",
      "                                                                                                  \n",
      " activation_268 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_269[0][0]']\n",
      "                                                                                                  \n",
      " block35_9_mixed (Concatenate)  (None, 32, 32, 128)  0           ['activation_263[0][0]',         \n",
      "                                                                  'activation_265[0][0]',         \n",
      "                                                                  'activation_268[0][0]']         \n",
      "                                                                                                  \n",
      " block35_9_conv (Conv2D)        (None, 32, 32, 320)  41280       ['block35_9_mixed[0][0]']        \n",
      "                                                                                                  \n",
      " block35_9 (Lambda)             (None, 32, 32, 320)  0           ['block35_8_ac[0][0]',           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                  'block35_9_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block35_9_ac (Activation)      (None, 32, 32, 320)  0           ['block35_9[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_278 (Conv2D)            (None, 32, 32, 32)   10240       ['block35_9_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_273 (Batch  (None, 32, 32, 32)  96          ['conv2d_278[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_272 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_273[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_276 (Conv2D)            (None, 32, 32, 32)   10240       ['block35_9_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_279 (Conv2D)            (None, 32, 32, 48)   13824       ['activation_272[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_271 (Batch  (None, 32, 32, 32)  96          ['conv2d_276[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_274 (Batch  (None, 32, 32, 48)  144         ['conv2d_279[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_270 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_271[0][0]']\n",
      "                                                                                                  \n",
      " activation_273 (Activation)    (None, 32, 32, 48)   0           ['batch_normalization_274[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_275 (Conv2D)            (None, 32, 32, 32)   10240       ['block35_9_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_277 (Conv2D)            (None, 32, 32, 32)   9216        ['activation_270[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_280 (Conv2D)            (None, 32, 32, 64)   27648       ['activation_273[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_270 (Batch  (None, 32, 32, 32)  96          ['conv2d_275[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_272 (Batch  (None, 32, 32, 32)  96          ['conv2d_277[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_275 (Batch  (None, 32, 32, 64)  192         ['conv2d_280[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_269 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_270[0][0]']\n",
      "                                                                                                  \n",
      " activation_271 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_272[0][0]']\n",
      "                                                                                                  \n",
      " activation_274 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_275[0][0]']\n",
      "                                                                                                  \n",
      " block35_10_mixed (Concatenate)  (None, 32, 32, 128)  0          ['activation_269[0][0]',         \n",
      "                                                                  'activation_271[0][0]',         \n",
      "                                                                  'activation_274[0][0]']         \n",
      "                                                                                                  \n",
      " block35_10_conv (Conv2D)       (None, 32, 32, 320)  41280       ['block35_10_mixed[0][0]']       \n",
      "                                                                                                  \n",
      " block35_10 (Lambda)            (None, 32, 32, 320)  0           ['block35_9_ac[0][0]',           \n",
      "                                                                  'block35_10_conv[0][0]']        \n",
      "                                                                                                  \n",
      " block35_10_ac (Activation)     (None, 32, 32, 320)  0           ['block35_10[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_282 (Conv2D)            (None, 32, 32, 256)  81920       ['block35_10_ac[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_277 (Batch  (None, 32, 32, 256)  768        ['conv2d_282[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_276 (Activation)    (None, 32, 32, 256)  0           ['batch_normalization_277[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_283 (Conv2D)            (None, 32, 32, 256)  589824      ['activation_276[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_278 (Batch  (None, 32, 32, 256)  768        ['conv2d_283[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_277 (Activation)    (None, 32, 32, 256)  0           ['batch_normalization_278[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_281 (Conv2D)            (None, 16, 16, 384)  1105920     ['block35_10_ac[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_284 (Conv2D)            (None, 16, 16, 384)  884736      ['activation_277[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_276 (Batch  (None, 16, 16, 384)  1152       ['conv2d_281[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_279 (Batch  (None, 16, 16, 384)  1152       ['conv2d_284[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_275 (Activation)    (None, 16, 16, 384)  0           ['batch_normalization_276[0][0]']\n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " activation_278 (Activation)    (None, 16, 16, 384)  0           ['batch_normalization_279[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 16, 16, 320)  0          ['block35_10_ac[0][0]']          \n",
      "                                                                                                  \n",
      " mixed_6a (Concatenate)         (None, 16, 16, 1088  0           ['activation_275[0][0]',         \n",
      "                                )                                 'activation_278[0][0]',         \n",
      "                                                                  'max_pooling2d_9[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_286 (Conv2D)            (None, 16, 16, 128)  139264      ['mixed_6a[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_281 (Batch  (None, 16, 16, 128)  384        ['conv2d_286[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_280 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_281[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_287 (Conv2D)            (None, 16, 16, 160)  143360      ['activation_280[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_282 (Batch  (None, 16, 16, 160)  480        ['conv2d_287[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_281 (Activation)    (None, 16, 16, 160)  0           ['batch_normalization_282[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_285 (Conv2D)            (None, 16, 16, 192)  208896      ['mixed_6a[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_288 (Conv2D)            (None, 16, 16, 192)  215040      ['activation_281[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_280 (Batch  (None, 16, 16, 192)  576        ['conv2d_285[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_283 (Batch  (None, 16, 16, 192)  576        ['conv2d_288[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_279 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_280[0][0]']\n",
      "                                                                                                  \n",
      " activation_282 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_283[0][0]']\n",
      "                                                                                                  \n",
      " block17_1_mixed (Concatenate)  (None, 16, 16, 384)  0           ['activation_279[0][0]',         \n",
      "                                                                  'activation_282[0][0]']         \n",
      "                                                                                                  \n",
      " block17_1_conv (Conv2D)        (None, 16, 16, 1088  418880      ['block17_1_mixed[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block17_1 (Lambda)             (None, 16, 16, 1088  0           ['mixed_6a[0][0]',               \n",
      "                                )                                 'block17_1_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block17_1_ac (Activation)      (None, 16, 16, 1088  0           ['block17_1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_290 (Conv2D)            (None, 16, 16, 128)  139264      ['block17_1_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_285 (Batch  (None, 16, 16, 128)  384        ['conv2d_290[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_284 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_285[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_291 (Conv2D)            (None, 16, 16, 160)  143360      ['activation_284[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_286 (Batch  (None, 16, 16, 160)  480        ['conv2d_291[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_285 (Activation)    (None, 16, 16, 160)  0           ['batch_normalization_286[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_289 (Conv2D)            (None, 16, 16, 192)  208896      ['block17_1_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_292 (Conv2D)            (None, 16, 16, 192)  215040      ['activation_285[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_284 (Batch  (None, 16, 16, 192)  576        ['conv2d_289[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_287 (Batch  (None, 16, 16, 192)  576        ['conv2d_292[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_283 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_284[0][0]']\n",
      "                                                                                                  \n",
      " activation_286 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_287[0][0]']\n",
      "                                                                                                  \n",
      " block17_2_mixed (Concatenate)  (None, 16, 16, 384)  0           ['activation_283[0][0]',         \n",
      "                                                                  'activation_286[0][0]']         \n",
      "                                                                                                  \n",
      " block17_2_conv (Conv2D)        (None, 16, 16, 1088  418880      ['block17_2_mixed[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block17_2 (Lambda)             (None, 16, 16, 1088  0           ['block17_1_ac[0][0]',           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                )                                 'block17_2_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block17_2_ac (Activation)      (None, 16, 16, 1088  0           ['block17_2[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_294 (Conv2D)            (None, 16, 16, 128)  139264      ['block17_2_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_289 (Batch  (None, 16, 16, 128)  384        ['conv2d_294[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_288 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_289[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_295 (Conv2D)            (None, 16, 16, 160)  143360      ['activation_288[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_290 (Batch  (None, 16, 16, 160)  480        ['conv2d_295[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_289 (Activation)    (None, 16, 16, 160)  0           ['batch_normalization_290[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_293 (Conv2D)            (None, 16, 16, 192)  208896      ['block17_2_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_296 (Conv2D)            (None, 16, 16, 192)  215040      ['activation_289[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_288 (Batch  (None, 16, 16, 192)  576        ['conv2d_293[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_291 (Batch  (None, 16, 16, 192)  576        ['conv2d_296[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_287 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_288[0][0]']\n",
      "                                                                                                  \n",
      " activation_290 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_291[0][0]']\n",
      "                                                                                                  \n",
      " block17_3_mixed (Concatenate)  (None, 16, 16, 384)  0           ['activation_287[0][0]',         \n",
      "                                                                  'activation_290[0][0]']         \n",
      "                                                                                                  \n",
      " block17_3_conv (Conv2D)        (None, 16, 16, 1088  418880      ['block17_3_mixed[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block17_3 (Lambda)             (None, 16, 16, 1088  0           ['block17_2_ac[0][0]',           \n",
      "                                )                                 'block17_3_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block17_3_ac (Activation)      (None, 16, 16, 1088  0           ['block17_3[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_298 (Conv2D)            (None, 16, 16, 128)  139264      ['block17_3_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_293 (Batch  (None, 16, 16, 128)  384        ['conv2d_298[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_292 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_293[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_299 (Conv2D)            (None, 16, 16, 160)  143360      ['activation_292[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_294 (Batch  (None, 16, 16, 160)  480        ['conv2d_299[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_293 (Activation)    (None, 16, 16, 160)  0           ['batch_normalization_294[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_297 (Conv2D)            (None, 16, 16, 192)  208896      ['block17_3_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_300 (Conv2D)            (None, 16, 16, 192)  215040      ['activation_293[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_292 (Batch  (None, 16, 16, 192)  576        ['conv2d_297[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_295 (Batch  (None, 16, 16, 192)  576        ['conv2d_300[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_291 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_292[0][0]']\n",
      "                                                                                                  \n",
      " activation_294 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_295[0][0]']\n",
      "                                                                                                  \n",
      " block17_4_mixed (Concatenate)  (None, 16, 16, 384)  0           ['activation_291[0][0]',         \n",
      "                                                                  'activation_294[0][0]']         \n",
      "                                                                                                  \n",
      " block17_4_conv (Conv2D)        (None, 16, 16, 1088  418880      ['block17_4_mixed[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block17_4 (Lambda)             (None, 16, 16, 1088  0           ['block17_3_ac[0][0]',           \n",
      "                                )                                 'block17_4_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block17_4_ac (Activation)      (None, 16, 16, 1088  0           ['block17_4[0][0]']              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_302 (Conv2D)            (None, 16, 16, 128)  139264      ['block17_4_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_297 (Batch  (None, 16, 16, 128)  384        ['conv2d_302[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_296 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_297[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_303 (Conv2D)            (None, 16, 16, 160)  143360      ['activation_296[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_298 (Batch  (None, 16, 16, 160)  480        ['conv2d_303[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_297 (Activation)    (None, 16, 16, 160)  0           ['batch_normalization_298[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_301 (Conv2D)            (None, 16, 16, 192)  208896      ['block17_4_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_304 (Conv2D)            (None, 16, 16, 192)  215040      ['activation_297[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_296 (Batch  (None, 16, 16, 192)  576        ['conv2d_301[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_299 (Batch  (None, 16, 16, 192)  576        ['conv2d_304[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_295 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_296[0][0]']\n",
      "                                                                                                  \n",
      " activation_298 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_299[0][0]']\n",
      "                                                                                                  \n",
      " block17_5_mixed (Concatenate)  (None, 16, 16, 384)  0           ['activation_295[0][0]',         \n",
      "                                                                  'activation_298[0][0]']         \n",
      "                                                                                                  \n",
      " block17_5_conv (Conv2D)        (None, 16, 16, 1088  418880      ['block17_5_mixed[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block17_5 (Lambda)             (None, 16, 16, 1088  0           ['block17_4_ac[0][0]',           \n",
      "                                )                                 'block17_5_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block17_5_ac (Activation)      (None, 16, 16, 1088  0           ['block17_5[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_306 (Conv2D)            (None, 16, 16, 128)  139264      ['block17_5_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_301 (Batch  (None, 16, 16, 128)  384        ['conv2d_306[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_300 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_301[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_307 (Conv2D)            (None, 16, 16, 160)  143360      ['activation_300[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_302 (Batch  (None, 16, 16, 160)  480        ['conv2d_307[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_301 (Activation)    (None, 16, 16, 160)  0           ['batch_normalization_302[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_305 (Conv2D)            (None, 16, 16, 192)  208896      ['block17_5_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_308 (Conv2D)            (None, 16, 16, 192)  215040      ['activation_301[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_300 (Batch  (None, 16, 16, 192)  576        ['conv2d_305[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_303 (Batch  (None, 16, 16, 192)  576        ['conv2d_308[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_299 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_300[0][0]']\n",
      "                                                                                                  \n",
      " activation_302 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_303[0][0]']\n",
      "                                                                                                  \n",
      " block17_6_mixed (Concatenate)  (None, 16, 16, 384)  0           ['activation_299[0][0]',         \n",
      "                                                                  'activation_302[0][0]']         \n",
      "                                                                                                  \n",
      " block17_6_conv (Conv2D)        (None, 16, 16, 1088  418880      ['block17_6_mixed[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block17_6 (Lambda)             (None, 16, 16, 1088  0           ['block17_5_ac[0][0]',           \n",
      "                                )                                 'block17_6_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block17_6_ac (Activation)      (None, 16, 16, 1088  0           ['block17_6[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_310 (Conv2D)            (None, 16, 16, 128)  139264      ['block17_6_ac[0][0]']           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " batch_normalization_305 (Batch  (None, 16, 16, 128)  384        ['conv2d_310[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_304 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_305[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_311 (Conv2D)            (None, 16, 16, 160)  143360      ['activation_304[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_306 (Batch  (None, 16, 16, 160)  480        ['conv2d_311[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_305 (Activation)    (None, 16, 16, 160)  0           ['batch_normalization_306[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_309 (Conv2D)            (None, 16, 16, 192)  208896      ['block17_6_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_312 (Conv2D)            (None, 16, 16, 192)  215040      ['activation_305[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_304 (Batch  (None, 16, 16, 192)  576        ['conv2d_309[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_307 (Batch  (None, 16, 16, 192)  576        ['conv2d_312[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_303 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_304[0][0]']\n",
      "                                                                                                  \n",
      " activation_306 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_307[0][0]']\n",
      "                                                                                                  \n",
      " block17_7_mixed (Concatenate)  (None, 16, 16, 384)  0           ['activation_303[0][0]',         \n",
      "                                                                  'activation_306[0][0]']         \n",
      "                                                                                                  \n",
      " block17_7_conv (Conv2D)        (None, 16, 16, 1088  418880      ['block17_7_mixed[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block17_7 (Lambda)             (None, 16, 16, 1088  0           ['block17_6_ac[0][0]',           \n",
      "                                )                                 'block17_7_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block17_7_ac (Activation)      (None, 16, 16, 1088  0           ['block17_7[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_314 (Conv2D)            (None, 16, 16, 128)  139264      ['block17_7_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_309 (Batch  (None, 16, 16, 128)  384        ['conv2d_314[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_308 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_309[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_315 (Conv2D)            (None, 16, 16, 160)  143360      ['activation_308[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_310 (Batch  (None, 16, 16, 160)  480        ['conv2d_315[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_309 (Activation)    (None, 16, 16, 160)  0           ['batch_normalization_310[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_313 (Conv2D)            (None, 16, 16, 192)  208896      ['block17_7_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_316 (Conv2D)            (None, 16, 16, 192)  215040      ['activation_309[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_308 (Batch  (None, 16, 16, 192)  576        ['conv2d_313[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_311 (Batch  (None, 16, 16, 192)  576        ['conv2d_316[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_307 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_308[0][0]']\n",
      "                                                                                                  \n",
      " activation_310 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_311[0][0]']\n",
      "                                                                                                  \n",
      " block17_8_mixed (Concatenate)  (None, 16, 16, 384)  0           ['activation_307[0][0]',         \n",
      "                                                                  'activation_310[0][0]']         \n",
      "                                                                                                  \n",
      " block17_8_conv (Conv2D)        (None, 16, 16, 1088  418880      ['block17_8_mixed[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block17_8 (Lambda)             (None, 16, 16, 1088  0           ['block17_7_ac[0][0]',           \n",
      "                                )                                 'block17_8_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block17_8_ac (Activation)      (None, 16, 16, 1088  0           ['block17_8[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_318 (Conv2D)            (None, 16, 16, 128)  139264      ['block17_8_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_313 (Batch  (None, 16, 16, 128)  384        ['conv2d_318[0][0]']             \n",
      " Normalization)                                                                                   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " activation_312 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_313[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_319 (Conv2D)            (None, 16, 16, 160)  143360      ['activation_312[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_314 (Batch  (None, 16, 16, 160)  480        ['conv2d_319[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_313 (Activation)    (None, 16, 16, 160)  0           ['batch_normalization_314[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_317 (Conv2D)            (None, 16, 16, 192)  208896      ['block17_8_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_320 (Conv2D)            (None, 16, 16, 192)  215040      ['activation_313[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_312 (Batch  (None, 16, 16, 192)  576        ['conv2d_317[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_315 (Batch  (None, 16, 16, 192)  576        ['conv2d_320[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_311 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_312[0][0]']\n",
      "                                                                                                  \n",
      " activation_314 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_315[0][0]']\n",
      "                                                                                                  \n",
      " block17_9_mixed (Concatenate)  (None, 16, 16, 384)  0           ['activation_311[0][0]',         \n",
      "                                                                  'activation_314[0][0]']         \n",
      "                                                                                                  \n",
      " block17_9_conv (Conv2D)        (None, 16, 16, 1088  418880      ['block17_9_mixed[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block17_9 (Lambda)             (None, 16, 16, 1088  0           ['block17_8_ac[0][0]',           \n",
      "                                )                                 'block17_9_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block17_9_ac (Activation)      (None, 16, 16, 1088  0           ['block17_9[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_322 (Conv2D)            (None, 16, 16, 128)  139264      ['block17_9_ac[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_317 (Batch  (None, 16, 16, 128)  384        ['conv2d_322[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_316 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_317[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_323 (Conv2D)            (None, 16, 16, 160)  143360      ['activation_316[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_318 (Batch  (None, 16, 16, 160)  480        ['conv2d_323[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_317 (Activation)    (None, 16, 16, 160)  0           ['batch_normalization_318[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_321 (Conv2D)            (None, 16, 16, 192)  208896      ['block17_9_ac[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_324 (Conv2D)            (None, 16, 16, 192)  215040      ['activation_317[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_316 (Batch  (None, 16, 16, 192)  576        ['conv2d_321[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_319 (Batch  (None, 16, 16, 192)  576        ['conv2d_324[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_315 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_316[0][0]']\n",
      "                                                                                                  \n",
      " activation_318 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_319[0][0]']\n",
      "                                                                                                  \n",
      " block17_10_mixed (Concatenate)  (None, 16, 16, 384)  0          ['activation_315[0][0]',         \n",
      "                                                                  'activation_318[0][0]']         \n",
      "                                                                                                  \n",
      " block17_10_conv (Conv2D)       (None, 16, 16, 1088  418880      ['block17_10_mixed[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block17_10 (Lambda)            (None, 16, 16, 1088  0           ['block17_9_ac[0][0]',           \n",
      "                                )                                 'block17_10_conv[0][0]']        \n",
      "                                                                                                  \n",
      " block17_10_ac (Activation)     (None, 16, 16, 1088  0           ['block17_10[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_326 (Conv2D)            (None, 16, 16, 128)  139264      ['block17_10_ac[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_321 (Batch  (None, 16, 16, 128)  384        ['conv2d_326[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_320 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_321[0][0]']\n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2d_327 (Conv2D)            (None, 16, 16, 160)  143360      ['activation_320[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_322 (Batch  (None, 16, 16, 160)  480        ['conv2d_327[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_321 (Activation)    (None, 16, 16, 160)  0           ['batch_normalization_322[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_325 (Conv2D)            (None, 16, 16, 192)  208896      ['block17_10_ac[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_328 (Conv2D)            (None, 16, 16, 192)  215040      ['activation_321[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_320 (Batch  (None, 16, 16, 192)  576        ['conv2d_325[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_323 (Batch  (None, 16, 16, 192)  576        ['conv2d_328[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_319 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_320[0][0]']\n",
      "                                                                                                  \n",
      " activation_322 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_323[0][0]']\n",
      "                                                                                                  \n",
      " block17_11_mixed (Concatenate)  (None, 16, 16, 384)  0          ['activation_319[0][0]',         \n",
      "                                                                  'activation_322[0][0]']         \n",
      "                                                                                                  \n",
      " block17_11_conv (Conv2D)       (None, 16, 16, 1088  418880      ['block17_11_mixed[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block17_11 (Lambda)            (None, 16, 16, 1088  0           ['block17_10_ac[0][0]',          \n",
      "                                )                                 'block17_11_conv[0][0]']        \n",
      "                                                                                                  \n",
      " block17_11_ac (Activation)     (None, 16, 16, 1088  0           ['block17_11[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_330 (Conv2D)            (None, 16, 16, 128)  139264      ['block17_11_ac[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_325 (Batch  (None, 16, 16, 128)  384        ['conv2d_330[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_324 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_325[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_331 (Conv2D)            (None, 16, 16, 160)  143360      ['activation_324[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_326 (Batch  (None, 16, 16, 160)  480        ['conv2d_331[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_325 (Activation)    (None, 16, 16, 160)  0           ['batch_normalization_326[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_329 (Conv2D)            (None, 16, 16, 192)  208896      ['block17_11_ac[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_332 (Conv2D)            (None, 16, 16, 192)  215040      ['activation_325[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_324 (Batch  (None, 16, 16, 192)  576        ['conv2d_329[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_327 (Batch  (None, 16, 16, 192)  576        ['conv2d_332[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_323 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_324[0][0]']\n",
      "                                                                                                  \n",
      " activation_326 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_327[0][0]']\n",
      "                                                                                                  \n",
      " block17_12_mixed (Concatenate)  (None, 16, 16, 384)  0          ['activation_323[0][0]',         \n",
      "                                                                  'activation_326[0][0]']         \n",
      "                                                                                                  \n",
      " block17_12_conv (Conv2D)       (None, 16, 16, 1088  418880      ['block17_12_mixed[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block17_12 (Lambda)            (None, 16, 16, 1088  0           ['block17_11_ac[0][0]',          \n",
      "                                )                                 'block17_12_conv[0][0]']        \n",
      "                                                                                                  \n",
      " block17_12_ac (Activation)     (None, 16, 16, 1088  0           ['block17_12[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_334 (Conv2D)            (None, 16, 16, 128)  139264      ['block17_12_ac[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_329 (Batch  (None, 16, 16, 128)  384        ['conv2d_334[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_328 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_329[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_335 (Conv2D)            (None, 16, 16, 160)  143360      ['activation_328[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_330 (Batch  (None, 16, 16, 160)  480        ['conv2d_335[0][0]']             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_329 (Activation)    (None, 16, 16, 160)  0           ['batch_normalization_330[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_333 (Conv2D)            (None, 16, 16, 192)  208896      ['block17_12_ac[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_336 (Conv2D)            (None, 16, 16, 192)  215040      ['activation_329[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_328 (Batch  (None, 16, 16, 192)  576        ['conv2d_333[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_331 (Batch  (None, 16, 16, 192)  576        ['conv2d_336[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_327 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_328[0][0]']\n",
      "                                                                                                  \n",
      " activation_330 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_331[0][0]']\n",
      "                                                                                                  \n",
      " block17_13_mixed (Concatenate)  (None, 16, 16, 384)  0          ['activation_327[0][0]',         \n",
      "                                                                  'activation_330[0][0]']         \n",
      "                                                                                                  \n",
      " block17_13_conv (Conv2D)       (None, 16, 16, 1088  418880      ['block17_13_mixed[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block17_13 (Lambda)            (None, 16, 16, 1088  0           ['block17_12_ac[0][0]',          \n",
      "                                )                                 'block17_13_conv[0][0]']        \n",
      "                                                                                                  \n",
      " block17_13_ac (Activation)     (None, 16, 16, 1088  0           ['block17_13[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_338 (Conv2D)            (None, 16, 16, 128)  139264      ['block17_13_ac[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_333 (Batch  (None, 16, 16, 128)  384        ['conv2d_338[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_332 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_333[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_339 (Conv2D)            (None, 16, 16, 160)  143360      ['activation_332[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_334 (Batch  (None, 16, 16, 160)  480        ['conv2d_339[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_333 (Activation)    (None, 16, 16, 160)  0           ['batch_normalization_334[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_337 (Conv2D)            (None, 16, 16, 192)  208896      ['block17_13_ac[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_340 (Conv2D)            (None, 16, 16, 192)  215040      ['activation_333[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_332 (Batch  (None, 16, 16, 192)  576        ['conv2d_337[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_335 (Batch  (None, 16, 16, 192)  576        ['conv2d_340[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_331 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_332[0][0]']\n",
      "                                                                                                  \n",
      " activation_334 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_335[0][0]']\n",
      "                                                                                                  \n",
      " block17_14_mixed (Concatenate)  (None, 16, 16, 384)  0          ['activation_331[0][0]',         \n",
      "                                                                  'activation_334[0][0]']         \n",
      "                                                                                                  \n",
      " block17_14_conv (Conv2D)       (None, 16, 16, 1088  418880      ['block17_14_mixed[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block17_14 (Lambda)            (None, 16, 16, 1088  0           ['block17_13_ac[0][0]',          \n",
      "                                )                                 'block17_14_conv[0][0]']        \n",
      "                                                                                                  \n",
      " block17_14_ac (Activation)     (None, 16, 16, 1088  0           ['block17_14[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_342 (Conv2D)            (None, 16, 16, 128)  139264      ['block17_14_ac[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_337 (Batch  (None, 16, 16, 128)  384        ['conv2d_342[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_336 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_337[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_343 (Conv2D)            (None, 16, 16, 160)  143360      ['activation_336[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_338 (Batch  (None, 16, 16, 160)  480        ['conv2d_343[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_337 (Activation)    (None, 16, 16, 160)  0           ['batch_normalization_338[0][0]']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv2d_341 (Conv2D)            (None, 16, 16, 192)  208896      ['block17_14_ac[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_344 (Conv2D)            (None, 16, 16, 192)  215040      ['activation_337[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_336 (Batch  (None, 16, 16, 192)  576        ['conv2d_341[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_339 (Batch  (None, 16, 16, 192)  576        ['conv2d_344[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_335 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_336[0][0]']\n",
      "                                                                                                  \n",
      " activation_338 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_339[0][0]']\n",
      "                                                                                                  \n",
      " block17_15_mixed (Concatenate)  (None, 16, 16, 384)  0          ['activation_335[0][0]',         \n",
      "                                                                  'activation_338[0][0]']         \n",
      "                                                                                                  \n",
      " block17_15_conv (Conv2D)       (None, 16, 16, 1088  418880      ['block17_15_mixed[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block17_15 (Lambda)            (None, 16, 16, 1088  0           ['block17_14_ac[0][0]',          \n",
      "                                )                                 'block17_15_conv[0][0]']        \n",
      "                                                                                                  \n",
      " block17_15_ac (Activation)     (None, 16, 16, 1088  0           ['block17_15[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_346 (Conv2D)            (None, 16, 16, 128)  139264      ['block17_15_ac[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_341 (Batch  (None, 16, 16, 128)  384        ['conv2d_346[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_340 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_341[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_347 (Conv2D)            (None, 16, 16, 160)  143360      ['activation_340[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_342 (Batch  (None, 16, 16, 160)  480        ['conv2d_347[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_341 (Activation)    (None, 16, 16, 160)  0           ['batch_normalization_342[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_345 (Conv2D)            (None, 16, 16, 192)  208896      ['block17_15_ac[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_348 (Conv2D)            (None, 16, 16, 192)  215040      ['activation_341[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_340 (Batch  (None, 16, 16, 192)  576        ['conv2d_345[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_343 (Batch  (None, 16, 16, 192)  576        ['conv2d_348[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_339 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_340[0][0]']\n",
      "                                                                                                  \n",
      " activation_342 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_343[0][0]']\n",
      "                                                                                                  \n",
      " block17_16_mixed (Concatenate)  (None, 16, 16, 384)  0          ['activation_339[0][0]',         \n",
      "                                                                  'activation_342[0][0]']         \n",
      "                                                                                                  \n",
      " block17_16_conv (Conv2D)       (None, 16, 16, 1088  418880      ['block17_16_mixed[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block17_16 (Lambda)            (None, 16, 16, 1088  0           ['block17_15_ac[0][0]',          \n",
      "                                )                                 'block17_16_conv[0][0]']        \n",
      "                                                                                                  \n",
      " block17_16_ac (Activation)     (None, 16, 16, 1088  0           ['block17_16[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_350 (Conv2D)            (None, 16, 16, 128)  139264      ['block17_16_ac[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_345 (Batch  (None, 16, 16, 128)  384        ['conv2d_350[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_344 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_345[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_351 (Conv2D)            (None, 16, 16, 160)  143360      ['activation_344[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_346 (Batch  (None, 16, 16, 160)  480        ['conv2d_351[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_345 (Activation)    (None, 16, 16, 160)  0           ['batch_normalization_346[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_349 (Conv2D)            (None, 16, 16, 192)  208896      ['block17_16_ac[0][0]']          \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2d_352 (Conv2D)            (None, 16, 16, 192)  215040      ['activation_345[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_344 (Batch  (None, 16, 16, 192)  576        ['conv2d_349[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_347 (Batch  (None, 16, 16, 192)  576        ['conv2d_352[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_343 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_344[0][0]']\n",
      "                                                                                                  \n",
      " activation_346 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_347[0][0]']\n",
      "                                                                                                  \n",
      " block17_17_mixed (Concatenate)  (None, 16, 16, 384)  0          ['activation_343[0][0]',         \n",
      "                                                                  'activation_346[0][0]']         \n",
      "                                                                                                  \n",
      " block17_17_conv (Conv2D)       (None, 16, 16, 1088  418880      ['block17_17_mixed[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block17_17 (Lambda)            (None, 16, 16, 1088  0           ['block17_16_ac[0][0]',          \n",
      "                                )                                 'block17_17_conv[0][0]']        \n",
      "                                                                                                  \n",
      " block17_17_ac (Activation)     (None, 16, 16, 1088  0           ['block17_17[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_354 (Conv2D)            (None, 16, 16, 128)  139264      ['block17_17_ac[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_349 (Batch  (None, 16, 16, 128)  384        ['conv2d_354[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_348 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_349[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_355 (Conv2D)            (None, 16, 16, 160)  143360      ['activation_348[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_350 (Batch  (None, 16, 16, 160)  480        ['conv2d_355[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_349 (Activation)    (None, 16, 16, 160)  0           ['batch_normalization_350[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_353 (Conv2D)            (None, 16, 16, 192)  208896      ['block17_17_ac[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_356 (Conv2D)            (None, 16, 16, 192)  215040      ['activation_349[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_348 (Batch  (None, 16, 16, 192)  576        ['conv2d_353[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_351 (Batch  (None, 16, 16, 192)  576        ['conv2d_356[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_347 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_348[0][0]']\n",
      "                                                                                                  \n",
      " activation_350 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_351[0][0]']\n",
      "                                                                                                  \n",
      " block17_18_mixed (Concatenate)  (None, 16, 16, 384)  0          ['activation_347[0][0]',         \n",
      "                                                                  'activation_350[0][0]']         \n",
      "                                                                                                  \n",
      " block17_18_conv (Conv2D)       (None, 16, 16, 1088  418880      ['block17_18_mixed[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block17_18 (Lambda)            (None, 16, 16, 1088  0           ['block17_17_ac[0][0]',          \n",
      "                                )                                 'block17_18_conv[0][0]']        \n",
      "                                                                                                  \n",
      " block17_18_ac (Activation)     (None, 16, 16, 1088  0           ['block17_18[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_358 (Conv2D)            (None, 16, 16, 128)  139264      ['block17_18_ac[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_353 (Batch  (None, 16, 16, 128)  384        ['conv2d_358[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_352 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_353[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_359 (Conv2D)            (None, 16, 16, 160)  143360      ['activation_352[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_354 (Batch  (None, 16, 16, 160)  480        ['conv2d_359[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_353 (Activation)    (None, 16, 16, 160)  0           ['batch_normalization_354[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_357 (Conv2D)            (None, 16, 16, 192)  208896      ['block17_18_ac[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_360 (Conv2D)            (None, 16, 16, 192)  215040      ['activation_353[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_352 (Batch  (None, 16, 16, 192)  576        ['conv2d_357[0][0]']             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_355 (Batch  (None, 16, 16, 192)  576        ['conv2d_360[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_351 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_352[0][0]']\n",
      "                                                                                                  \n",
      " activation_354 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_355[0][0]']\n",
      "                                                                                                  \n",
      " block17_19_mixed (Concatenate)  (None, 16, 16, 384)  0          ['activation_351[0][0]',         \n",
      "                                                                  'activation_354[0][0]']         \n",
      "                                                                                                  \n",
      " block17_19_conv (Conv2D)       (None, 16, 16, 1088  418880      ['block17_19_mixed[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block17_19 (Lambda)            (None, 16, 16, 1088  0           ['block17_18_ac[0][0]',          \n",
      "                                )                                 'block17_19_conv[0][0]']        \n",
      "                                                                                                  \n",
      " block17_19_ac (Activation)     (None, 16, 16, 1088  0           ['block17_19[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_362 (Conv2D)            (None, 16, 16, 128)  139264      ['block17_19_ac[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_357 (Batch  (None, 16, 16, 128)  384        ['conv2d_362[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_356 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_357[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_363 (Conv2D)            (None, 16, 16, 160)  143360      ['activation_356[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_358 (Batch  (None, 16, 16, 160)  480        ['conv2d_363[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_357 (Activation)    (None, 16, 16, 160)  0           ['batch_normalization_358[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_361 (Conv2D)            (None, 16, 16, 192)  208896      ['block17_19_ac[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_364 (Conv2D)            (None, 16, 16, 192)  215040      ['activation_357[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_356 (Batch  (None, 16, 16, 192)  576        ['conv2d_361[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_359 (Batch  (None, 16, 16, 192)  576        ['conv2d_364[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_355 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_356[0][0]']\n",
      "                                                                                                  \n",
      " activation_358 (Activation)    (None, 16, 16, 192)  0           ['batch_normalization_359[0][0]']\n",
      "                                                                                                  \n",
      " block17_20_mixed (Concatenate)  (None, 16, 16, 384)  0          ['activation_355[0][0]',         \n",
      "                                                                  'activation_358[0][0]']         \n",
      "                                                                                                  \n",
      " block17_20_conv (Conv2D)       (None, 16, 16, 1088  418880      ['block17_20_mixed[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block17_20 (Lambda)            (None, 16, 16, 1088  0           ['block17_19_ac[0][0]',          \n",
      "                                )                                 'block17_20_conv[0][0]']        \n",
      "                                                                                                  \n",
      " block17_20_ac (Activation)     (None, 16, 16, 1088  0           ['block17_20[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_369 (Conv2D)            (None, 16, 16, 256)  278528      ['block17_20_ac[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_364 (Batch  (None, 16, 16, 256)  768        ['conv2d_369[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_363 (Activation)    (None, 16, 16, 256)  0           ['batch_normalization_364[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_365 (Conv2D)            (None, 16, 16, 256)  278528      ['block17_20_ac[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_367 (Conv2D)            (None, 16, 16, 256)  278528      ['block17_20_ac[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_370 (Conv2D)            (None, 16, 16, 288)  663552      ['activation_363[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_360 (Batch  (None, 16, 16, 256)  768        ['conv2d_365[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_362 (Batch  (None, 16, 16, 256)  768        ['conv2d_367[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_365 (Batch  (None, 16, 16, 288)  864        ['conv2d_370[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " activation_359 (Activation)    (None, 16, 16, 256)  0           ['batch_normalization_360[0][0]']\n",
      "                                                                                                  \n",
      " activation_361 (Activation)    (None, 16, 16, 256)  0           ['batch_normalization_362[0][0]']\n",
      "                                                                                                  \n",
      " activation_364 (Activation)    (None, 16, 16, 288)  0           ['batch_normalization_365[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_366 (Conv2D)            (None, 8, 8, 384)    884736      ['activation_359[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_368 (Conv2D)            (None, 8, 8, 288)    663552      ['activation_361[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_371 (Conv2D)            (None, 8, 8, 320)    829440      ['activation_364[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_361 (Batch  (None, 8, 8, 384)   1152        ['conv2d_366[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_363 (Batch  (None, 8, 8, 288)   864         ['conv2d_368[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_366 (Batch  (None, 8, 8, 320)   960         ['conv2d_371[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_360 (Activation)    (None, 8, 8, 384)    0           ['batch_normalization_361[0][0]']\n",
      "                                                                                                  \n",
      " activation_362 (Activation)    (None, 8, 8, 288)    0           ['batch_normalization_363[0][0]']\n",
      "                                                                                                  \n",
      " activation_365 (Activation)    (None, 8, 8, 320)    0           ['batch_normalization_366[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooling2D  (None, 8, 8, 1088)  0           ['block17_20_ac[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " mixed_7a (Concatenate)         (None, 8, 8, 2080)   0           ['activation_360[0][0]',         \n",
      "                                                                  'activation_362[0][0]',         \n",
      "                                                                  'activation_365[0][0]',         \n",
      "                                                                  'max_pooling2d_10[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_373 (Conv2D)            (None, 8, 8, 192)    399360      ['mixed_7a[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_368 (Batch  (None, 8, 8, 192)   576         ['conv2d_373[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_367 (Activation)    (None, 8, 8, 192)    0           ['batch_normalization_368[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_374 (Conv2D)            (None, 8, 8, 224)    129024      ['activation_367[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_369 (Batch  (None, 8, 8, 224)   672         ['conv2d_374[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_368 (Activation)    (None, 8, 8, 224)    0           ['batch_normalization_369[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_372 (Conv2D)            (None, 8, 8, 192)    399360      ['mixed_7a[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_375 (Conv2D)            (None, 8, 8, 256)    172032      ['activation_368[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_367 (Batch  (None, 8, 8, 192)   576         ['conv2d_372[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_370 (Batch  (None, 8, 8, 256)   768         ['conv2d_375[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_366 (Activation)    (None, 8, 8, 192)    0           ['batch_normalization_367[0][0]']\n",
      "                                                                                                  \n",
      " activation_369 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_370[0][0]']\n",
      "                                                                                                  \n",
      " block8_1_mixed (Concatenate)   (None, 8, 8, 448)    0           ['activation_366[0][0]',         \n",
      "                                                                  'activation_369[0][0]']         \n",
      "                                                                                                  \n",
      " block8_1_conv (Conv2D)         (None, 8, 8, 2080)   933920      ['block8_1_mixed[0][0]']         \n",
      "                                                                                                  \n",
      " block8_1 (Lambda)              (None, 8, 8, 2080)   0           ['mixed_7a[0][0]',               \n",
      "                                                                  'block8_1_conv[0][0]']          \n",
      "                                                                                                  \n",
      " block8_1_ac (Activation)       (None, 8, 8, 2080)   0           ['block8_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_377 (Conv2D)            (None, 8, 8, 192)    399360      ['block8_1_ac[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_372 (Batch  (None, 8, 8, 192)   576         ['conv2d_377[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_371 (Activation)    (None, 8, 8, 192)    0           ['batch_normalization_372[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_378 (Conv2D)            (None, 8, 8, 224)    129024      ['activation_371[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_373 (Batch  (None, 8, 8, 224)   672         ['conv2d_378[0][0]']             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_372 (Activation)    (None, 8, 8, 224)    0           ['batch_normalization_373[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_376 (Conv2D)            (None, 8, 8, 192)    399360      ['block8_1_ac[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_379 (Conv2D)            (None, 8, 8, 256)    172032      ['activation_372[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_371 (Batch  (None, 8, 8, 192)   576         ['conv2d_376[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_374 (Batch  (None, 8, 8, 256)   768         ['conv2d_379[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_370 (Activation)    (None, 8, 8, 192)    0           ['batch_normalization_371[0][0]']\n",
      "                                                                                                  \n",
      " activation_373 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_374[0][0]']\n",
      "                                                                                                  \n",
      " block8_2_mixed (Concatenate)   (None, 8, 8, 448)    0           ['activation_370[0][0]',         \n",
      "                                                                  'activation_373[0][0]']         \n",
      "                                                                                                  \n",
      " block8_2_conv (Conv2D)         (None, 8, 8, 2080)   933920      ['block8_2_mixed[0][0]']         \n",
      "                                                                                                  \n",
      " block8_2 (Lambda)              (None, 8, 8, 2080)   0           ['block8_1_ac[0][0]',            \n",
      "                                                                  'block8_2_conv[0][0]']          \n",
      "                                                                                                  \n",
      " block8_2_ac (Activation)       (None, 8, 8, 2080)   0           ['block8_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_381 (Conv2D)            (None, 8, 8, 192)    399360      ['block8_2_ac[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_376 (Batch  (None, 8, 8, 192)   576         ['conv2d_381[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_375 (Activation)    (None, 8, 8, 192)    0           ['batch_normalization_376[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_382 (Conv2D)            (None, 8, 8, 224)    129024      ['activation_375[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_377 (Batch  (None, 8, 8, 224)   672         ['conv2d_382[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_376 (Activation)    (None, 8, 8, 224)    0           ['batch_normalization_377[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_380 (Conv2D)            (None, 8, 8, 192)    399360      ['block8_2_ac[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_383 (Conv2D)            (None, 8, 8, 256)    172032      ['activation_376[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_375 (Batch  (None, 8, 8, 192)   576         ['conv2d_380[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_378 (Batch  (None, 8, 8, 256)   768         ['conv2d_383[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_374 (Activation)    (None, 8, 8, 192)    0           ['batch_normalization_375[0][0]']\n",
      "                                                                                                  \n",
      " activation_377 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_378[0][0]']\n",
      "                                                                                                  \n",
      " block8_3_mixed (Concatenate)   (None, 8, 8, 448)    0           ['activation_374[0][0]',         \n",
      "                                                                  'activation_377[0][0]']         \n",
      "                                                                                                  \n",
      " block8_3_conv (Conv2D)         (None, 8, 8, 2080)   933920      ['block8_3_mixed[0][0]']         \n",
      "                                                                                                  \n",
      " block8_3 (Lambda)              (None, 8, 8, 2080)   0           ['block8_2_ac[0][0]',            \n",
      "                                                                  'block8_3_conv[0][0]']          \n",
      "                                                                                                  \n",
      " block8_3_ac (Activation)       (None, 8, 8, 2080)   0           ['block8_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_385 (Conv2D)            (None, 8, 8, 192)    399360      ['block8_3_ac[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_380 (Batch  (None, 8, 8, 192)   576         ['conv2d_385[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_379 (Activation)    (None, 8, 8, 192)    0           ['batch_normalization_380[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_386 (Conv2D)            (None, 8, 8, 224)    129024      ['activation_379[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_381 (Batch  (None, 8, 8, 224)   672         ['conv2d_386[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_380 (Activation)    (None, 8, 8, 224)    0           ['batch_normalization_381[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_384 (Conv2D)            (None, 8, 8, 192)    399360      ['block8_3_ac[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_387 (Conv2D)            (None, 8, 8, 256)    172032      ['activation_380[0][0]']         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " batch_normalization_379 (Batch  (None, 8, 8, 192)   576         ['conv2d_384[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_382 (Batch  (None, 8, 8, 256)   768         ['conv2d_387[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_378 (Activation)    (None, 8, 8, 192)    0           ['batch_normalization_379[0][0]']\n",
      "                                                                                                  \n",
      " activation_381 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_382[0][0]']\n",
      "                                                                                                  \n",
      " block8_4_mixed (Concatenate)   (None, 8, 8, 448)    0           ['activation_378[0][0]',         \n",
      "                                                                  'activation_381[0][0]']         \n",
      "                                                                                                  \n",
      " block8_4_conv (Conv2D)         (None, 8, 8, 2080)   933920      ['block8_4_mixed[0][0]']         \n",
      "                                                                                                  \n",
      " block8_4 (Lambda)              (None, 8, 8, 2080)   0           ['block8_3_ac[0][0]',            \n",
      "                                                                  'block8_4_conv[0][0]']          \n",
      "                                                                                                  \n",
      " block8_4_ac (Activation)       (None, 8, 8, 2080)   0           ['block8_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_389 (Conv2D)            (None, 8, 8, 192)    399360      ['block8_4_ac[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_384 (Batch  (None, 8, 8, 192)   576         ['conv2d_389[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_383 (Activation)    (None, 8, 8, 192)    0           ['batch_normalization_384[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_390 (Conv2D)            (None, 8, 8, 224)    129024      ['activation_383[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_385 (Batch  (None, 8, 8, 224)   672         ['conv2d_390[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_384 (Activation)    (None, 8, 8, 224)    0           ['batch_normalization_385[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_388 (Conv2D)            (None, 8, 8, 192)    399360      ['block8_4_ac[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_391 (Conv2D)            (None, 8, 8, 256)    172032      ['activation_384[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_383 (Batch  (None, 8, 8, 192)   576         ['conv2d_388[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_386 (Batch  (None, 8, 8, 256)   768         ['conv2d_391[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_382 (Activation)    (None, 8, 8, 192)    0           ['batch_normalization_383[0][0]']\n",
      "                                                                                                  \n",
      " activation_385 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_386[0][0]']\n",
      "                                                                                                  \n",
      " block8_5_mixed (Concatenate)   (None, 8, 8, 448)    0           ['activation_382[0][0]',         \n",
      "                                                                  'activation_385[0][0]']         \n",
      "                                                                                                  \n",
      " block8_5_conv (Conv2D)         (None, 8, 8, 2080)   933920      ['block8_5_mixed[0][0]']         \n",
      "                                                                                                  \n",
      " block8_5 (Lambda)              (None, 8, 8, 2080)   0           ['block8_4_ac[0][0]',            \n",
      "                                                                  'block8_5_conv[0][0]']          \n",
      "                                                                                                  \n",
      " block8_5_ac (Activation)       (None, 8, 8, 2080)   0           ['block8_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_393 (Conv2D)            (None, 8, 8, 192)    399360      ['block8_5_ac[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_388 (Batch  (None, 8, 8, 192)   576         ['conv2d_393[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_387 (Activation)    (None, 8, 8, 192)    0           ['batch_normalization_388[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_394 (Conv2D)            (None, 8, 8, 224)    129024      ['activation_387[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_389 (Batch  (None, 8, 8, 224)   672         ['conv2d_394[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_388 (Activation)    (None, 8, 8, 224)    0           ['batch_normalization_389[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_392 (Conv2D)            (None, 8, 8, 192)    399360      ['block8_5_ac[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_395 (Conv2D)            (None, 8, 8, 256)    172032      ['activation_388[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_387 (Batch  (None, 8, 8, 192)   576         ['conv2d_392[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_390 (Batch  (None, 8, 8, 256)   768         ['conv2d_395[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " activation_386 (Activation)    (None, 8, 8, 192)    0           ['batch_normalization_387[0][0]']\n",
      "                                                                                                  \n",
      " activation_389 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_390[0][0]']\n",
      "                                                                                                  \n",
      " block8_6_mixed (Concatenate)   (None, 8, 8, 448)    0           ['activation_386[0][0]',         \n",
      "                                                                  'activation_389[0][0]']         \n",
      "                                                                                                  \n",
      " block8_6_conv (Conv2D)         (None, 8, 8, 2080)   933920      ['block8_6_mixed[0][0]']         \n",
      "                                                                                                  \n",
      " block8_6 (Lambda)              (None, 8, 8, 2080)   0           ['block8_5_ac[0][0]',            \n",
      "                                                                  'block8_6_conv[0][0]']          \n",
      "                                                                                                  \n",
      " block8_6_ac (Activation)       (None, 8, 8, 2080)   0           ['block8_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_397 (Conv2D)            (None, 8, 8, 192)    399360      ['block8_6_ac[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_392 (Batch  (None, 8, 8, 192)   576         ['conv2d_397[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_391 (Activation)    (None, 8, 8, 192)    0           ['batch_normalization_392[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_398 (Conv2D)            (None, 8, 8, 224)    129024      ['activation_391[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_393 (Batch  (None, 8, 8, 224)   672         ['conv2d_398[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_392 (Activation)    (None, 8, 8, 224)    0           ['batch_normalization_393[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_396 (Conv2D)            (None, 8, 8, 192)    399360      ['block8_6_ac[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_399 (Conv2D)            (None, 8, 8, 256)    172032      ['activation_392[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_391 (Batch  (None, 8, 8, 192)   576         ['conv2d_396[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_394 (Batch  (None, 8, 8, 256)   768         ['conv2d_399[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_390 (Activation)    (None, 8, 8, 192)    0           ['batch_normalization_391[0][0]']\n",
      "                                                                                                  \n",
      " activation_393 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_394[0][0]']\n",
      "                                                                                                  \n",
      " block8_7_mixed (Concatenate)   (None, 8, 8, 448)    0           ['activation_390[0][0]',         \n",
      "                                                                  'activation_393[0][0]']         \n",
      "                                                                                                  \n",
      " block8_7_conv (Conv2D)         (None, 8, 8, 2080)   933920      ['block8_7_mixed[0][0]']         \n",
      "                                                                                                  \n",
      " block8_7 (Lambda)              (None, 8, 8, 2080)   0           ['block8_6_ac[0][0]',            \n",
      "                                                                  'block8_7_conv[0][0]']          \n",
      "                                                                                                  \n",
      " block8_7_ac (Activation)       (None, 8, 8, 2080)   0           ['block8_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_401 (Conv2D)            (None, 8, 8, 192)    399360      ['block8_7_ac[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_396 (Batch  (None, 8, 8, 192)   576         ['conv2d_401[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_395 (Activation)    (None, 8, 8, 192)    0           ['batch_normalization_396[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_402 (Conv2D)            (None, 8, 8, 224)    129024      ['activation_395[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_397 (Batch  (None, 8, 8, 224)   672         ['conv2d_402[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_396 (Activation)    (None, 8, 8, 224)    0           ['batch_normalization_397[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_400 (Conv2D)            (None, 8, 8, 192)    399360      ['block8_7_ac[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_403 (Conv2D)            (None, 8, 8, 256)    172032      ['activation_396[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_395 (Batch  (None, 8, 8, 192)   576         ['conv2d_400[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_398 (Batch  (None, 8, 8, 256)   768         ['conv2d_403[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_394 (Activation)    (None, 8, 8, 192)    0           ['batch_normalization_395[0][0]']\n",
      "                                                                                                  \n",
      " activation_397 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_398[0][0]']\n",
      "                                                                                                  \n",
      " block8_8_mixed (Concatenate)   (None, 8, 8, 448)    0           ['activation_394[0][0]',         \n",
      "                                                                  'activation_397[0][0]']         \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block8_8_conv (Conv2D)         (None, 8, 8, 2080)   933920      ['block8_8_mixed[0][0]']         \n",
      "                                                                                                  \n",
      " block8_8 (Lambda)              (None, 8, 8, 2080)   0           ['block8_7_ac[0][0]',            \n",
      "                                                                  'block8_8_conv[0][0]']          \n",
      "                                                                                                  \n",
      " block8_8_ac (Activation)       (None, 8, 8, 2080)   0           ['block8_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_405 (Conv2D)            (None, 8, 8, 192)    399360      ['block8_8_ac[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_400 (Batch  (None, 8, 8, 192)   576         ['conv2d_405[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_399 (Activation)    (None, 8, 8, 192)    0           ['batch_normalization_400[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_406 (Conv2D)            (None, 8, 8, 224)    129024      ['activation_399[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_401 (Batch  (None, 8, 8, 224)   672         ['conv2d_406[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_400 (Activation)    (None, 8, 8, 224)    0           ['batch_normalization_401[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_404 (Conv2D)            (None, 8, 8, 192)    399360      ['block8_8_ac[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_407 (Conv2D)            (None, 8, 8, 256)    172032      ['activation_400[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_399 (Batch  (None, 8, 8, 192)   576         ['conv2d_404[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_402 (Batch  (None, 8, 8, 256)   768         ['conv2d_407[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_398 (Activation)    (None, 8, 8, 192)    0           ['batch_normalization_399[0][0]']\n",
      "                                                                                                  \n",
      " activation_401 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_402[0][0]']\n",
      "                                                                                                  \n",
      " block8_9_mixed (Concatenate)   (None, 8, 8, 448)    0           ['activation_398[0][0]',         \n",
      "                                                                  'activation_401[0][0]']         \n",
      "                                                                                                  \n",
      " block8_9_conv (Conv2D)         (None, 8, 8, 2080)   933920      ['block8_9_mixed[0][0]']         \n",
      "                                                                                                  \n",
      " block8_9 (Lambda)              (None, 8, 8, 2080)   0           ['block8_8_ac[0][0]',            \n",
      "                                                                  'block8_9_conv[0][0]']          \n",
      "                                                                                                  \n",
      " block8_9_ac (Activation)       (None, 8, 8, 2080)   0           ['block8_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_409 (Conv2D)            (None, 8, 8, 192)    399360      ['block8_9_ac[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_404 (Batch  (None, 8, 8, 192)   576         ['conv2d_409[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_403 (Activation)    (None, 8, 8, 192)    0           ['batch_normalization_404[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_410 (Conv2D)            (None, 8, 8, 224)    129024      ['activation_403[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_405 (Batch  (None, 8, 8, 224)   672         ['conv2d_410[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_404 (Activation)    (None, 8, 8, 224)    0           ['batch_normalization_405[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_408 (Conv2D)            (None, 8, 8, 192)    399360      ['block8_9_ac[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_411 (Conv2D)            (None, 8, 8, 256)    172032      ['activation_404[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_403 (Batch  (None, 8, 8, 192)   576         ['conv2d_408[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_406 (Batch  (None, 8, 8, 256)   768         ['conv2d_411[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_402 (Activation)    (None, 8, 8, 192)    0           ['batch_normalization_403[0][0]']\n",
      "                                                                                                  \n",
      " activation_405 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_406[0][0]']\n",
      "                                                                                                  \n",
      " block8_10_mixed (Concatenate)  (None, 8, 8, 448)    0           ['activation_402[0][0]',         \n",
      "                                                                  'activation_405[0][0]']         \n",
      "                                                                                                  \n",
      " block8_10_conv (Conv2D)        (None, 8, 8, 2080)   933920      ['block8_10_mixed[0][0]']        \n",
      "                                                                                                  \n",
      " block8_10 (Lambda)             (None, 8, 8, 2080)   0           ['block8_9_ac[0][0]',            \n",
      "                                                                  'block8_10_conv[0][0]']         \n",
      "                                                                                                  \n",
      " conv_7b (Conv2D)               (None, 8, 8, 1536)   3194880     ['block8_10[0][0]']              \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv_7b_bn (BatchNormalization  (None, 8, 8, 1536)  4608        ['conv_7b[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv_7b_ac (Activation)        (None, 8, 8, 1536)   0           ['conv_7b_bn[0][0]']             \n",
      "                                                                                                  \n",
      " decoder_stage0_upsampling (UpS  (None, 16, 16, 1536  0          ['conv_7b_ac[0][0]']             \n",
      " ampling2D)                     )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage0_concat (Concate  (None, 16, 16, 2624  0          ['decoder_stage0_upsampling[0][0]\n",
      " nate)                          )                                ',                               \n",
      "                                                                  'block17_20_ac[0][0]']          \n",
      "                                                                                                  \n",
      " decoder_stage0a_conv (Conv2D)  (None, 16, 16, 256)  6045696     ['decoder_stage0_concat[0][0]']  \n",
      "                                                                                                  \n",
      " decoder_stage0a_bn (BatchNorma  (None, 16, 16, 256)  1024       ['decoder_stage0a_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage0a_relu (Activati  (None, 16, 16, 256)  0          ['decoder_stage0a_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage0b_conv (Conv2D)  (None, 16, 16, 256)  589824      ['decoder_stage0a_relu[0][0]']   \n",
      "                                                                                                  \n",
      " decoder_stage0b_bn (BatchNorma  (None, 16, 16, 256)  1024       ['decoder_stage0b_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage0b_relu (Activati  (None, 16, 16, 256)  0          ['decoder_stage0b_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage1_upsampling (UpS  (None, 32, 32, 256)  0          ['decoder_stage0b_relu[0][0]']   \n",
      " ampling2D)                                                                                       \n",
      "                                                                                                  \n",
      " decoder_stage1_concat (Concate  (None, 32, 32, 576)  0          ['decoder_stage1_upsampling[0][0]\n",
      " nate)                                                           ',                               \n",
      "                                                                  'block35_10_ac[0][0]']          \n",
      "                                                                                                  \n",
      " decoder_stage1a_conv (Conv2D)  (None, 32, 32, 128)  663552      ['decoder_stage1_concat[0][0]']  \n",
      "                                                                                                  \n",
      " decoder_stage1a_bn (BatchNorma  (None, 32, 32, 128)  512        ['decoder_stage1a_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage1a_relu (Activati  (None, 32, 32, 128)  0          ['decoder_stage1a_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage1b_conv (Conv2D)  (None, 32, 32, 128)  147456      ['decoder_stage1a_relu[0][0]']   \n",
      "                                                                                                  \n",
      " decoder_stage1b_bn (BatchNorma  (None, 32, 32, 128)  512        ['decoder_stage1b_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage1b_relu (Activati  (None, 32, 32, 128)  0          ['decoder_stage1b_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage2_upsampling (UpS  (None, 64, 64, 128)  0          ['decoder_stage1b_relu[0][0]']   \n",
      " ampling2D)                                                                                       \n",
      "                                                                                                  \n",
      " decoder_stage2_concat (Concate  (None, 64, 64, 320)  0          ['decoder_stage2_upsampling[0][0]\n",
      " nate)                                                           ',                               \n",
      "                                                                  'activation_207[0][0]']         \n",
      "                                                                                                  \n",
      " decoder_stage2a_conv (Conv2D)  (None, 64, 64, 64)   184320      ['decoder_stage2_concat[0][0]']  \n",
      "                                                                                                  \n",
      " decoder_stage2a_bn (BatchNorma  (None, 64, 64, 64)  256         ['decoder_stage2a_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage2a_relu (Activati  (None, 64, 64, 64)  0           ['decoder_stage2a_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage2b_conv (Conv2D)  (None, 64, 64, 64)   36864       ['decoder_stage2a_relu[0][0]']   \n",
      "                                                                                                  \n",
      " decoder_stage2b_bn (BatchNorma  (None, 64, 64, 64)  256         ['decoder_stage2b_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " decoder_stage2b_relu (Activati  (None, 64, 64, 64)  0           ['decoder_stage2b_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_stage3_upsampling (UpS  (None, 128, 128, 64  0          ['decoder_stage2b_relu[0][0]']   \n",
      " ampling2D)                     )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage3_concat (Concate  (None, 128, 128, 12  0          ['decoder_stage3_upsampling[0][0]\n",
      " nate)                          8)                               ',                               \n",
      "                                                                  'activation_205[0][0]']         \n",
      "                                                                                                  \n",
      " decoder_stage3a_conv (Conv2D)  (None, 128, 128, 32  36864       ['decoder_stage3_concat[0][0]']  \n",
      "                                )                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " decoder_stage3a_bn (BatchNorma  (None, 128, 128, 32  128        ['decoder_stage3a_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage3a_relu (Activati  (None, 128, 128, 32  0          ['decoder_stage3a_bn[0][0]']     \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage3b_conv (Conv2D)  (None, 128, 128, 32  9216        ['decoder_stage3a_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage3b_bn (BatchNorma  (None, 128, 128, 32  128        ['decoder_stage3b_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage3b_relu (Activati  (None, 128, 128, 32  0          ['decoder_stage3b_bn[0][0]']     \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage4_upsampling (UpS  (None, 256, 256, 32  0          ['decoder_stage3b_relu[0][0]']   \n",
      " ampling2D)                     )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage4a_conv (Conv2D)  (None, 256, 256, 16  4608        ['decoder_stage4_upsampling[0][0]\n",
      "                                )                                ']                               \n",
      "                                                                                                  \n",
      " decoder_stage4a_bn (BatchNorma  (None, 256, 256, 16  64         ['decoder_stage4a_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage4a_relu (Activati  (None, 256, 256, 16  0          ['decoder_stage4a_bn[0][0]']     \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage4b_conv (Conv2D)  (None, 256, 256, 16  2304        ['decoder_stage4a_relu[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage4b_bn (BatchNorma  (None, 256, 256, 16  64         ['decoder_stage4b_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " decoder_stage4b_relu (Activati  (None, 256, 256, 16  0          ['decoder_stage4b_bn[0][0]']     \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " final_conv (Conv2D)            (None, 256, 256, 6)  870         ['decoder_stage4b_relu[0][0]']   \n",
      "                                                                                                  \n",
      " softmax (Activation)           (None, 256, 256, 6)  0           ['final_conv[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 62,062,278\n",
      "Trainable params: 61,999,750\n",
      "Non-trainable params: 62,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(\n",
    "    learning_rate = 0.001), loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False), metrics=[mean_iou, dice_coef, \"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b4055817",
   "metadata": {},
   "source": [
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))\n",
    "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd3c8b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(lr0, s, warmup_epochs=10, min_lr=1e-6):\n",
    "    \"\"\"\n",
    "    Exponential Decay Learning Rate Scheduler with Warmup and Minimum Learning Rate.\n",
    "    \n",
    "    Args:\n",
    "        lr0: float, initial learning rate.\n",
    "        s: float, decay step (controls the rate of decay).\n",
    "        warmup_epochs: int, number of epochs to keep the initial learning rate constant.\n",
    "        min_lr: float, minimum learning rate after decay.\n",
    "    \n",
    "    Returns:\n",
    "        A function that computes the learning rate based on the current epoch.\n",
    "    \"\"\"\n",
    "    def exponential_decay_fn(epoch):\n",
    "        if epoch < warmup_epochs:\n",
    "            return lr0  # Warmup: Keep initial learning rate for `warmup_epochs`\n",
    "        lr = lr0 * 0.1 ** ((epoch - warmup_epochs) / s)\n",
    "        return max(lr, min_lr)  # Ensure learning rate does not go below `min_lr`\n",
    "    \n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(0.001, 60)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(\n",
    "    exponential_decay_fn,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath = 'kics_summer_model.h5',\n",
    "    save_best_only = True, \n",
    "#   save_weights_only = False,\n",
    "    monitor = 'val_loss', \n",
    "    mode = 'auto', \n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "earlystop = EarlyStopping(\n",
    "    monitor = 'val_loss', \n",
    "    min_delta = 0.001, \n",
    "    patience = 12, \n",
    "    mode = 'auto', \n",
    "    verbose = 1,\n",
    "    restore_best_weights = True\n",
    ")\n",
    "\n",
    "csvlogger = CSVLogger(\n",
    "    filename= \"kics_summer_model.csv\",\n",
    "    separator = \",\",\n",
    "    append = False\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint, earlystop, csvlogger, lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be55284e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 710 images belonging to 1 classes.\n",
      "Found 710 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "a, b = next(TrainAugmentGenerator(train_images_dir = train_images, train_masks_dir = train_masks, batch_size = batch_size, target_size = image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c0fede1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 710 images belonging to 1 classes.\n",
      "Found 710 images belonging to 1 classes.\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 1.3845 - mean_iou: 0.2203 - dice_coef: 0.3351 - accuracy: 0.4941Found 213 images belonging to 1 classes.\n",
      "Found 213 images belonging to 1 classes.\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 83.16804, saving model to kics_summer_model.h5\n",
      "18/18 [==============================] - 17s 405ms/step - loss: 1.3845 - mean_iou: 0.2203 - dice_coef: 0.3351 - accuracy: 0.4941 - val_loss: 83.1680 - val_mean_iou: 0.0410 - val_dice_coef: 0.1217 - val_accuracy: 0.1228 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.8362 - mean_iou: 0.3473 - dice_coef: 0.5601 - accuracy: 0.7172\n",
      "Epoch 2: val_loss did not improve from 83.16804\n",
      "18/18 [==============================] - 3s 192ms/step - loss: 0.8362 - mean_iou: 0.3473 - dice_coef: 0.5601 - accuracy: 0.7172 - val_loss: 3575.5820 - val_mean_iou: 0.0233 - val_dice_coef: 0.1145 - val_accuracy: 0.1166 - lr: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.8077 - mean_iou: 0.3689 - dice_coef: 0.5993 - accuracy: 0.7251\n",
      "Epoch 3: val_loss did not improve from 83.16804\n",
      "18/18 [==============================] - 3s 189ms/step - loss: 0.8077 - mean_iou: 0.3689 - dice_coef: 0.5993 - accuracy: 0.7251 - val_loss: 149.5056 - val_mean_iou: 0.1181 - val_dice_coef: 0.2896 - val_accuracy: 0.2858 - lr: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.7914 - mean_iou: 0.4179 - dice_coef: 0.5943 - accuracy: 0.7254\n",
      "Epoch 4: val_loss improved from 83.16804 to 43.30377, saving model to kics_summer_model.h5\n",
      "18/18 [==============================] - 5s 289ms/step - loss: 0.7914 - mean_iou: 0.4179 - dice_coef: 0.5943 - accuracy: 0.7254 - val_loss: 43.3038 - val_mean_iou: 0.1929 - val_dice_coef: 0.5232 - val_accuracy: 0.5429 - lr: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.6919 - mean_iou: 0.4374 - dice_coef: 0.6368 - accuracy: 0.7605\n",
      "Epoch 5: val_loss improved from 43.30377 to 30.19147, saving model to kics_summer_model.h5\n",
      "18/18 [==============================] - 6s 325ms/step - loss: 0.6919 - mean_iou: 0.4374 - dice_coef: 0.6368 - accuracy: 0.7605 - val_loss: 30.1915 - val_mean_iou: 0.3267 - val_dice_coef: 0.5191 - val_accuracy: 0.6018 - lr: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.6435 - mean_iou: 0.4618 - dice_coef: 0.6701 - accuracy: 0.7792\n",
      "Epoch 6: val_loss improved from 30.19147 to 22.04728, saving model to kics_summer_model.h5\n",
      "18/18 [==============================] - 5s 285ms/step - loss: 0.6435 - mean_iou: 0.4618 - dice_coef: 0.6701 - accuracy: 0.7792 - val_loss: 22.0473 - val_mean_iou: 0.4226 - val_dice_coef: 0.6409 - val_accuracy: 0.7457 - lr: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.6342 - mean_iou: 0.4713 - dice_coef: 0.6722 - accuracy: 0.7799\n",
      "Epoch 7: val_loss did not improve from 22.04728\n",
      "18/18 [==============================] - 3s 193ms/step - loss: 0.6342 - mean_iou: 0.4713 - dice_coef: 0.6722 - accuracy: 0.7799 - val_loss: 1621.0543 - val_mean_iou: 0.1483 - val_dice_coef: 0.2561 - val_accuracy: 0.3044 - lr: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.6120 - mean_iou: 0.4836 - dice_coef: 0.6931 - accuracy: 0.7909\n",
      "Epoch 8: val_loss did not improve from 22.04728\n",
      "18/18 [==============================] - 3s 188ms/step - loss: 0.6120 - mean_iou: 0.4836 - dice_coef: 0.6931 - accuracy: 0.7909 - val_loss: 757.1643 - val_mean_iou: 0.2154 - val_dice_coef: 0.4550 - val_accuracy: 0.4866 - lr: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.5977 - mean_iou: 0.4896 - dice_coef: 0.6864 - accuracy: 0.7855\n",
      "Epoch 9: val_loss did not improve from 22.04728\n",
      "18/18 [==============================] - 3s 188ms/step - loss: 0.5977 - mean_iou: 0.4896 - dice_coef: 0.6864 - accuracy: 0.7855 - val_loss: 38.1308 - val_mean_iou: 0.2728 - val_dice_coef: 0.5077 - val_accuracy: 0.5758 - lr: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.5847 - mean_iou: 0.5071 - dice_coef: 0.6979 - accuracy: 0.7961\n",
      "Epoch 10: val_loss improved from 22.04728 to 0.64104, saving model to kics_summer_model.h5\n",
      "18/18 [==============================] - 5s 294ms/step - loss: 0.5847 - mean_iou: 0.5071 - dice_coef: 0.6979 - accuracy: 0.7961 - val_loss: 0.6410 - val_mean_iou: 0.4250 - val_dice_coef: 0.7009 - val_accuracy: 0.7695 - lr: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.6398 - mean_iou: 0.4881 - dice_coef: 0.6767 - accuracy: 0.7693\n",
      "Epoch 11: val_loss did not improve from 0.64104\n",
      "18/18 [==============================] - 3s 190ms/step - loss: 0.6398 - mean_iou: 0.4881 - dice_coef: 0.6767 - accuracy: 0.7693 - val_loss: 0.7315 - val_mean_iou: 0.4016 - val_dice_coef: 0.6673 - val_accuracy: 0.7279 - lr: 0.0010\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0009623506263980886.\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.5747 - mean_iou: 0.4991 - dice_coef: 0.7052 - accuracy: 0.8008\n",
      "Epoch 12: val_loss did not improve from 0.64104\n",
      "18/18 [==============================] - 3s 186ms/step - loss: 0.5747 - mean_iou: 0.4991 - dice_coef: 0.7052 - accuracy: 0.8008 - val_loss: 0.6518 - val_mean_iou: 0.4924 - val_dice_coef: 0.7287 - val_accuracy: 0.7977 - lr: 9.6235e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0009261187281287935.\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.5337 - mean_iou: 0.5085 - dice_coef: 0.7237 - accuracy: 0.8155\n",
      "Epoch 13: val_loss did not improve from 0.64104\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.5337 - mean_iou: 0.5085 - dice_coef: 0.7237 - accuracy: 0.8155 - val_loss: 0.7081 - val_mean_iou: 0.4192 - val_dice_coef: 0.6750 - val_accuracy: 0.7396 - lr: 9.2612e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0008912509381337456.\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.5693 - mean_iou: 0.4979 - dice_coef: 0.7083 - accuracy: 0.7996\n",
      "Epoch 14: val_loss did not improve from 0.64104\n",
      "18/18 [==============================] - 3s 190ms/step - loss: 0.5693 - mean_iou: 0.4979 - dice_coef: 0.7083 - accuracy: 0.7996 - val_loss: 0.6955 - val_mean_iou: 0.4377 - val_dice_coef: 0.6927 - val_accuracy: 0.7413 - lr: 8.9125e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0008576958985908942.\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.5145 - mean_iou: 0.5268 - dice_coef: 0.7249 - accuracy: 0.8227\n",
      "Epoch 15: val_loss improved from 0.64104 to 0.58569, saving model to kics_summer_model.h5\n",
      "18/18 [==============================] - 5s 283ms/step - loss: 0.5145 - mean_iou: 0.5268 - dice_coef: 0.7249 - accuracy: 0.8227 - val_loss: 0.5857 - val_mean_iou: 0.4856 - val_dice_coef: 0.7261 - val_accuracy: 0.7970 - lr: 8.5770e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0008254041852680184.\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4747 - mean_iou: 0.5543 - dice_coef: 0.7511 - accuracy: 0.8339\n",
      "Epoch 16: val_loss did not improve from 0.58569\n",
      "18/18 [==============================] - 3s 191ms/step - loss: 0.4747 - mean_iou: 0.5543 - dice_coef: 0.7511 - accuracy: 0.8339 - val_loss: 0.8474 - val_mean_iou: 0.3990 - val_dice_coef: 0.6704 - val_accuracy: 0.7152 - lr: 8.2540e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0007943282347242815.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.5167 - mean_iou: 0.5324 - dice_coef: 0.7331 - accuracy: 0.8180\n",
      "Epoch 17: val_loss improved from 0.58569 to 0.53632, saving model to kics_summer_model.h5\n",
      "18/18 [==============================] - 5s 289ms/step - loss: 0.5167 - mean_iou: 0.5324 - dice_coef: 0.7331 - accuracy: 0.8180 - val_loss: 0.5363 - val_mean_iou: 0.4860 - val_dice_coef: 0.7432 - val_accuracy: 0.8145 - lr: 7.9433e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0007644222742526003.\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4563 - mean_iou: 0.5645 - dice_coef: 0.7585 - accuracy: 0.8386\n",
      "Epoch 18: val_loss did not improve from 0.53632\n",
      "18/18 [==============================] - 3s 194ms/step - loss: 0.4563 - mean_iou: 0.5645 - dice_coef: 0.7585 - accuracy: 0.8386 - val_loss: 0.5920 - val_mean_iou: 0.4760 - val_dice_coef: 0.7270 - val_accuracy: 0.7877 - lr: 7.6442e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0007356422544596414.\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4931 - mean_iou: 0.5381 - dice_coef: 0.7488 - accuracy: 0.8253\n",
      "Epoch 19: val_loss improved from 0.53632 to 0.50795, saving model to kics_summer_model.h5\n",
      "18/18 [==============================] - 5s 281ms/step - loss: 0.4931 - mean_iou: 0.5381 - dice_coef: 0.7488 - accuracy: 0.8253 - val_loss: 0.5080 - val_mean_iou: 0.5067 - val_dice_coef: 0.7564 - val_accuracy: 0.8151 - lr: 7.3564e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0007079457843841379.\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4410 - mean_iou: 0.5585 - dice_coef: 0.7645 - accuracy: 0.8454\n",
      "Epoch 20: val_loss improved from 0.50795 to 0.49913, saving model to kics_summer_model.h5\n",
      "18/18 [==============================] - 5s 286ms/step - loss: 0.4410 - mean_iou: 0.5585 - dice_coef: 0.7645 - accuracy: 0.8454 - val_loss: 0.4991 - val_mean_iou: 0.5084 - val_dice_coef: 0.7576 - val_accuracy: 0.8191 - lr: 7.0795e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0006812920690579614.\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4426 - mean_iou: 0.5678 - dice_coef: 0.7701 - accuracy: 0.8461\n",
      "Epoch 21: val_loss improved from 0.49913 to 0.44173, saving model to kics_summer_model.h5\n",
      "18/18 [==============================] - 5s 292ms/step - loss: 0.4426 - mean_iou: 0.5678 - dice_coef: 0.7701 - accuracy: 0.8461 - val_loss: 0.4417 - val_mean_iou: 0.5574 - val_dice_coef: 0.7776 - val_accuracy: 0.8415 - lr: 6.8129e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0006556418494179789.\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4610 - mean_iou: 0.5591 - dice_coef: 0.7580 - accuracy: 0.8360\n",
      "Epoch 22: val_loss did not improve from 0.44173\n",
      "18/18 [==============================] - 3s 190ms/step - loss: 0.4610 - mean_iou: 0.5591 - dice_coef: 0.7580 - accuracy: 0.8360 - val_loss: 0.4904 - val_mean_iou: 0.5200 - val_dice_coef: 0.7698 - val_accuracy: 0.8270 - lr: 6.5564e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0006309573444801933.\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4634 - mean_iou: 0.5584 - dice_coef: 0.7632 - accuracy: 0.8406\n",
      "Epoch 23: val_loss did not improve from 0.44173\n",
      "18/18 [==============================] - 3s 192ms/step - loss: 0.4634 - mean_iou: 0.5584 - dice_coef: 0.7632 - accuracy: 0.8406 - val_loss: 0.5038 - val_mean_iou: 0.5182 - val_dice_coef: 0.7760 - val_accuracy: 0.8258 - lr: 6.3096e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0006072021956909885.\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4245 - mean_iou: 0.5659 - dice_coef: 0.7734 - accuracy: 0.8485\n",
      "Epoch 24: val_loss did not improve from 0.44173\n",
      "18/18 [==============================] - 3s 188ms/step - loss: 0.4245 - mean_iou: 0.5659 - dice_coef: 0.7734 - accuracy: 0.8485 - val_loss: 0.4804 - val_mean_iou: 0.4930 - val_dice_coef: 0.7811 - val_accuracy: 0.8178 - lr: 6.0720e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0005843414133735176.\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4193 - mean_iou: 0.5588 - dice_coef: 0.7831 - accuracy: 0.8538\n",
      "Epoch 25: val_loss did not improve from 0.44173\n",
      "18/18 [==============================] - 3s 189ms/step - loss: 0.4193 - mean_iou: 0.5588 - dice_coef: 0.7831 - accuracy: 0.8538 - val_loss: 0.5811 - val_mean_iou: 0.5293 - val_dice_coef: 0.7712 - val_accuracy: 0.8151 - lr: 5.8434e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0005623413251903491.\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4223 - mean_iou: 0.5790 - dice_coef: 0.7743 - accuracy: 0.8497\n",
      "Epoch 26: val_loss improved from 0.44173 to 0.40298, saving model to kics_summer_model.h5\n",
      "18/18 [==============================] - 5s 286ms/step - loss: 0.4223 - mean_iou: 0.5790 - dice_coef: 0.7743 - accuracy: 0.8497 - val_loss: 0.4030 - val_mean_iou: 0.5531 - val_dice_coef: 0.7961 - val_accuracy: 0.8539 - lr: 5.6234e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.0005411695265464636.\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3722 - mean_iou: 0.5924 - dice_coef: 0.7989 - accuracy: 0.8667\n",
      "Epoch 27: val_loss improved from 0.40298 to 0.39094, saving model to kics_summer_model.h5\n",
      "18/18 [==============================] - 5s 289ms/step - loss: 0.3722 - mean_iou: 0.5924 - dice_coef: 0.7989 - accuracy: 0.8667 - val_loss: 0.3909 - val_mean_iou: 0.5806 - val_dice_coef: 0.7973 - val_accuracy: 0.8631 - lr: 5.4117e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.0005207948328595464.\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4004 - mean_iou: 0.5841 - dice_coef: 0.7922 - accuracy: 0.8576\n",
      "Epoch 28: val_loss did not improve from 0.39094\n",
      "18/18 [==============================] - 3s 192ms/step - loss: 0.4004 - mean_iou: 0.5841 - dice_coef: 0.7922 - accuracy: 0.8576 - val_loss: 0.4167 - val_mean_iou: 0.5606 - val_dice_coef: 0.7873 - val_accuracy: 0.8501 - lr: 5.2079e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.0005011872336272724.\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4112 - mean_iou: 0.5802 - dice_coef: 0.7858 - accuracy: 0.8566\n",
      "Epoch 29: val_loss improved from 0.39094 to 0.38647, saving model to kics_summer_model.h5\n",
      "18/18 [==============================] - 5s 288ms/step - loss: 0.4112 - mean_iou: 0.5802 - dice_coef: 0.7858 - accuracy: 0.8566 - val_loss: 0.3865 - val_mean_iou: 0.5966 - val_dice_coef: 0.7985 - val_accuracy: 0.8622 - lr: 5.0119e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0004823178482239307.\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3835 - mean_iou: 0.5906 - dice_coef: 0.7968 - accuracy: 0.8664\n",
      "Epoch 30: val_loss did not improve from 0.38647\n",
      "18/18 [==============================] - 3s 194ms/step - loss: 0.3835 - mean_iou: 0.5906 - dice_coef: 0.7968 - accuracy: 0.8664 - val_loss: 0.4069 - val_mean_iou: 0.5608 - val_dice_coef: 0.7926 - val_accuracy: 0.8538 - lr: 4.8232e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.00046415888336127795.\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4001 - mean_iou: 0.5942 - dice_coef: 0.7879 - accuracy: 0.8572\n",
      "Epoch 31: val_loss did not improve from 0.38647\n",
      "18/18 [==============================] - 3s 190ms/step - loss: 0.4001 - mean_iou: 0.5942 - dice_coef: 0.7879 - accuracy: 0.8572 - val_loss: 0.4295 - val_mean_iou: 0.5575 - val_dice_coef: 0.7894 - val_accuracy: 0.8435 - lr: 4.6416e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00044668359215096316.\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3664 - mean_iou: 0.6015 - dice_coef: 0.8057 - accuracy: 0.8712\n",
      "Epoch 32: val_loss did not improve from 0.38647\n",
      "18/18 [==============================] - 3s 190ms/step - loss: 0.3664 - mean_iou: 0.6015 - dice_coef: 0.8057 - accuracy: 0.8712 - val_loss: 0.4046 - val_mean_iou: 0.5633 - val_dice_coef: 0.7976 - val_accuracy: 0.8551 - lr: 4.4668e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.00042986623470822773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3785 - mean_iou: 0.5923 - dice_coef: 0.8025 - accuracy: 0.8666\n",
      "Epoch 33: val_loss improved from 0.38647 to 0.38540, saving model to kics_summer_model.h5\n",
      "18/18 [==============================] - 5s 281ms/step - loss: 0.3785 - mean_iou: 0.5923 - dice_coef: 0.8025 - accuracy: 0.8666 - val_loss: 0.3854 - val_mean_iou: 0.5830 - val_dice_coef: 0.7990 - val_accuracy: 0.8596 - lr: 4.2987e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0004136820402388507.\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3633 - mean_iou: 0.5958 - dice_coef: 0.8042 - accuracy: 0.8707\n",
      "Epoch 34: val_loss did not improve from 0.38540\n",
      "18/18 [==============================] - 3s 190ms/step - loss: 0.3633 - mean_iou: 0.5958 - dice_coef: 0.8042 - accuracy: 0.8707 - val_loss: 0.3962 - val_mean_iou: 0.5766 - val_dice_coef: 0.7921 - val_accuracy: 0.8553 - lr: 4.1368e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.00039810717055349724.\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3189 - mean_iou: 0.6077 - dice_coef: 0.8221 - accuracy: 0.8876\n",
      "Epoch 35: val_loss improved from 0.38540 to 0.36342, saving model to kics_summer_model.h5\n",
      "18/18 [==============================] - 5s 289ms/step - loss: 0.3189 - mean_iou: 0.6077 - dice_coef: 0.8221 - accuracy: 0.8876 - val_loss: 0.3634 - val_mean_iou: 0.5866 - val_dice_coef: 0.8065 - val_accuracy: 0.8694 - lr: 3.9811e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.00038311868495572875.\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3412 - mean_iou: 0.6086 - dice_coef: 0.8177 - accuracy: 0.8758\n",
      "Epoch 36: val_loss did not improve from 0.36342\n",
      "18/18 [==============================] - 3s 192ms/step - loss: 0.3412 - mean_iou: 0.6086 - dice_coef: 0.8177 - accuracy: 0.8758 - val_loss: 0.3798 - val_mean_iou: 0.5921 - val_dice_coef: 0.7931 - val_accuracy: 0.8627 - lr: 3.8312e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.00036869450645195755.\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3342 - mean_iou: 0.6103 - dice_coef: 0.8220 - accuracy: 0.8805\n",
      "Epoch 37: val_loss improved from 0.36342 to 0.34577, saving model to kics_summer_model.h5\n",
      "18/18 [==============================] - 5s 286ms/step - loss: 0.3342 - mean_iou: 0.6103 - dice_coef: 0.8220 - accuracy: 0.8805 - val_loss: 0.3458 - val_mean_iou: 0.5982 - val_dice_coef: 0.8101 - val_accuracy: 0.8748 - lr: 3.6869e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0003548133892335755.\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3335 - mean_iou: 0.6207 - dice_coef: 0.8183 - accuracy: 0.8789\n",
      "Epoch 38: val_loss did not improve from 0.34577\n",
      "18/18 [==============================] - 4s 197ms/step - loss: 0.3335 - mean_iou: 0.6207 - dice_coef: 0.8183 - accuracy: 0.8789 - val_loss: 0.3790 - val_mean_iou: 0.5981 - val_dice_coef: 0.8014 - val_accuracy: 0.8640 - lr: 3.5481e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0003414548873833602.\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3475 - mean_iou: 0.6079 - dice_coef: 0.8131 - accuracy: 0.8772\n",
      "Epoch 39: val_loss did not improve from 0.34577\n",
      "18/18 [==============================] - 3s 196ms/step - loss: 0.3475 - mean_iou: 0.6079 - dice_coef: 0.8131 - accuracy: 0.8772 - val_loss: 0.3473 - val_mean_iou: 0.6001 - val_dice_coef: 0.8176 - val_accuracy: 0.8766 - lr: 3.4145e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.00032859932476006547.\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3468 - mean_iou: 0.6105 - dice_coef: 0.8127 - accuracy: 0.8754\n",
      "Epoch 40: val_loss did not improve from 0.34577\n",
      "18/18 [==============================] - 3s 193ms/step - loss: 0.3468 - mean_iou: 0.6105 - dice_coef: 0.8127 - accuracy: 0.8754 - val_loss: 0.3531 - val_mean_iou: 0.6034 - val_dice_coef: 0.8176 - val_accuracy: 0.8735 - lr: 3.2860e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.00031622776601683794.\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3108 - mean_iou: 0.6182 - dice_coef: 0.8262 - accuracy: 0.8846\n",
      "Epoch 41: val_loss did not improve from 0.34577\n",
      "18/18 [==============================] - 3s 194ms/step - loss: 0.3108 - mean_iou: 0.6182 - dice_coef: 0.8262 - accuracy: 0.8846 - val_loss: 0.3465 - val_mean_iou: 0.6088 - val_dice_coef: 0.8107 - val_accuracy: 0.8747 - lr: 3.1623e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.00030432198871077214.\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3003 - mean_iou: 0.6282 - dice_coef: 0.8373 - accuracy: 0.8925\n",
      "Epoch 42: val_loss did not improve from 0.34577\n",
      "18/18 [==============================] - 3s 193ms/step - loss: 0.3003 - mean_iou: 0.6282 - dice_coef: 0.8373 - accuracy: 0.8925 - val_loss: 0.4268 - val_mean_iou: 0.5643 - val_dice_coef: 0.7743 - val_accuracy: 0.8445 - lr: 3.0432e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0002928644564625237.\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3042 - mean_iou: 0.6395 - dice_coef: 0.8374 - accuracy: 0.8907\n",
      "Epoch 43: val_loss did not improve from 0.34577\n",
      "18/18 [==============================] - 3s 191ms/step - loss: 0.3042 - mean_iou: 0.6395 - dice_coef: 0.8374 - accuracy: 0.8907 - val_loss: 0.3576 - val_mean_iou: 0.5951 - val_dice_coef: 0.8029 - val_accuracy: 0.8706 - lr: 2.9286e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0002818382931264454.\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3243 - mean_iou: 0.6354 - dice_coef: 0.8260 - accuracy: 0.8836\n",
      "Epoch 44: val_loss did not improve from 0.34577\n",
      "18/18 [==============================] - 3s 192ms/step - loss: 0.3243 - mean_iou: 0.6354 - dice_coef: 0.8260 - accuracy: 0.8836 - val_loss: 0.3607 - val_mean_iou: 0.6089 - val_dice_coef: 0.8080 - val_accuracy: 0.8691 - lr: 2.8184e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.00027122725793320287.\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3124 - mean_iou: 0.6301 - dice_coef: 0.8305 - accuracy: 0.8869\n",
      "Epoch 45: val_loss improved from 0.34577 to 0.33112, saving model to kics_summer_model.h5\n",
      "18/18 [==============================] - 5s 282ms/step - loss: 0.3124 - mean_iou: 0.6301 - dice_coef: 0.8305 - accuracy: 0.8869 - val_loss: 0.3311 - val_mean_iou: 0.6126 - val_dice_coef: 0.8309 - val_accuracy: 0.8804 - lr: 2.7123e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.00026101572156825363.\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2946 - mean_iou: 0.6346 - dice_coef: 0.8348 - accuracy: 0.8891\n",
      "Epoch 46: val_loss did not improve from 0.33112\n",
      "18/18 [==============================] - 3s 190ms/step - loss: 0.2946 - mean_iou: 0.6346 - dice_coef: 0.8348 - accuracy: 0.8891 - val_loss: 0.3448 - val_mean_iou: 0.6018 - val_dice_coef: 0.8244 - val_accuracy: 0.8765 - lr: 2.6102e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.000251188643150958.\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2787 - mean_iou: 0.6371 - dice_coef: 0.8479 - accuracy: 0.8979\n",
      "Epoch 47: val_loss improved from 0.33112 to 0.31671, saving model to kics_summer_model.h5\n",
      "18/18 [==============================] - 5s 286ms/step - loss: 0.2787 - mean_iou: 0.6371 - dice_coef: 0.8479 - accuracy: 0.8979 - val_loss: 0.3167 - val_mean_iou: 0.6140 - val_dice_coef: 0.8369 - val_accuracy: 0.8850 - lr: 2.5119e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0002417315480804104.\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3044 - mean_iou: 0.6318 - dice_coef: 0.8342 - accuracy: 0.8877\n",
      "Epoch 48: val_loss did not improve from 0.31671\n",
      "18/18 [==============================] - 3s 189ms/step - loss: 0.3044 - mean_iou: 0.6318 - dice_coef: 0.8342 - accuracy: 0.8877 - val_loss: 0.3282 - val_mean_iou: 0.6124 - val_dice_coef: 0.8341 - val_accuracy: 0.8820 - lr: 2.4173e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.00023263050671536265.\n",
      "Epoch 49/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 0.3001 - mean_iou: 0.6327 - dice_coef: 0.8352 - accuracy: 0.8931\n",
      "Epoch 49: val_loss did not improve from 0.31671\n",
      "18/18 [==============================] - 3s 190ms/step - loss: 0.3001 - mean_iou: 0.6327 - dice_coef: 0.8352 - accuracy: 0.8931 - val_loss: 0.3350 - val_mean_iou: 0.6029 - val_dice_coef: 0.8258 - val_accuracy: 0.8790 - lr: 2.3263e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.00022387211385683394.\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3130 - mean_iou: 0.6294 - dice_coef: 0.8309 - accuracy: 0.8857\n",
      "Epoch 50: val_loss did not improve from 0.31671\n",
      "18/18 [==============================] - 3s 188ms/step - loss: 0.3130 - mean_iou: 0.6294 - dice_coef: 0.8309 - accuracy: 0.8857 - val_loss: 0.3373 - val_mean_iou: 0.6094 - val_dice_coef: 0.8260 - val_accuracy: 0.8769 - lr: 2.2387e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.0002154434690031884.\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2702 - mean_iou: 0.6445 - dice_coef: 0.8495 - accuracy: 0.9008\n",
      "Epoch 51: val_loss did not improve from 0.31671\n",
      "18/18 [==============================] - 3s 191ms/step - loss: 0.2702 - mean_iou: 0.6445 - dice_coef: 0.8495 - accuracy: 0.9008 - val_loss: 0.3302 - val_mean_iou: 0.6273 - val_dice_coef: 0.8352 - val_accuracy: 0.8826 - lr: 2.1544e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.0002073321573485955.\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2635 - mean_iou: 0.6448 - dice_coef: 0.8563 - accuracy: 0.9035\n",
      "Epoch 52: val_loss improved from 0.31671 to 0.31534, saving model to kics_summer_model.h5\n",
      "18/18 [==============================] - 5s 281ms/step - loss: 0.2635 - mean_iou: 0.6448 - dice_coef: 0.8563 - accuracy: 0.9035 - val_loss: 0.3153 - val_mean_iou: 0.6188 - val_dice_coef: 0.8376 - val_accuracy: 0.8852 - lr: 2.0733e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.000199526231496888.\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3134 - mean_iou: 0.6366 - dice_coef: 0.8289 - accuracy: 0.8839\n",
      "Epoch 53: val_loss did not improve from 0.31534\n",
      "18/18 [==============================] - 3s 190ms/step - loss: 0.3134 - mean_iou: 0.6366 - dice_coef: 0.8289 - accuracy: 0.8839 - val_loss: 0.3215 - val_mean_iou: 0.6192 - val_dice_coef: 0.8334 - val_accuracy: 0.8821 - lr: 1.9953e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.00019201419386388017.\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2849 - mean_iou: 0.6329 - dice_coef: 0.8425 - accuracy: 0.8959\n",
      "Epoch 54: val_loss did not improve from 0.31534\n",
      "18/18 [==============================] - 3s 191ms/step - loss: 0.2849 - mean_iou: 0.6329 - dice_coef: 0.8425 - accuracy: 0.8959 - val_loss: 0.3326 - val_mean_iou: 0.6129 - val_dice_coef: 0.8294 - val_accuracy: 0.8810 - lr: 1.9201e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.00018478497974222914.\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2581 - mean_iou: 0.6501 - dice_coef: 0.8560 - accuracy: 0.9041\n",
      "Epoch 55: val_loss did not improve from 0.31534\n",
      "18/18 [==============================] - 3s 192ms/step - loss: 0.2581 - mean_iou: 0.6501 - dice_coef: 0.8560 - accuracy: 0.9041 - val_loss: 0.3321 - val_mean_iou: 0.6140 - val_dice_coef: 0.8295 - val_accuracy: 0.8786 - lr: 1.8478e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.0001778279410038923.\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2589 - mean_iou: 0.6403 - dice_coef: 0.8568 - accuracy: 0.9019\n",
      "Epoch 56: val_loss did not improve from 0.31534\n",
      "18/18 [==============================] - 3s 190ms/step - loss: 0.2589 - mean_iou: 0.6403 - dice_coef: 0.8568 - accuracy: 0.9019 - val_loss: 0.3204 - val_mean_iou: 0.6173 - val_dice_coef: 0.8323 - val_accuracy: 0.8831 - lr: 1.7783e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.00017113283041617807.\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2911 - mean_iou: 0.6450 - dice_coef: 0.8402 - accuracy: 0.8920\n",
      "Epoch 57: val_loss improved from 0.31534 to 0.31500, saving model to kics_summer_model.h5\n",
      "18/18 [==============================] - 5s 275ms/step - loss: 0.2911 - mean_iou: 0.6450 - dice_coef: 0.8402 - accuracy: 0.8920 - val_loss: 0.3150 - val_mean_iou: 0.6282 - val_dice_coef: 0.8341 - val_accuracy: 0.8846 - lr: 1.7113e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.00016468978654828688.\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2747 - mean_iou: 0.6433 - dice_coef: 0.8459 - accuracy: 0.8972\n",
      "Epoch 58: val_loss did not improve from 0.31500\n",
      "18/18 [==============================] - 3s 191ms/step - loss: 0.2747 - mean_iou: 0.6433 - dice_coef: 0.8459 - accuracy: 0.8972 - val_loss: 0.3354 - val_mean_iou: 0.6137 - val_dice_coef: 0.8360 - val_accuracy: 0.8817 - lr: 1.6469e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.00015848931924611134.\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2895 - mean_iou: 0.6418 - dice_coef: 0.8408 - accuracy: 0.8951\n",
      "Epoch 59: val_loss did not improve from 0.31500\n",
      "18/18 [==============================] - 3s 191ms/step - loss: 0.2895 - mean_iou: 0.6418 - dice_coef: 0.8408 - accuracy: 0.8951 - val_loss: 0.3247 - val_mean_iou: 0.6194 - val_dice_coef: 0.8375 - val_accuracy: 0.8856 - lr: 1.5849e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.0001525222956539019.\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2654 - mean_iou: 0.6431 - dice_coef: 0.8547 - accuracy: 0.9002\n",
      "Epoch 60: val_loss did not improve from 0.31500\n",
      "18/18 [==============================] - 3s 190ms/step - loss: 0.2654 - mean_iou: 0.6431 - dice_coef: 0.8547 - accuracy: 0.9002 - val_loss: 0.3556 - val_mean_iou: 0.6182 - val_dice_coef: 0.8365 - val_accuracy: 0.8800 - lr: 1.5252e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.00014677992676220695.\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2661 - mean_iou: 0.6563 - dice_coef: 0.8496 - accuracy: 0.8983\n",
      "Epoch 61: val_loss improved from 0.31500 to 0.31058, saving model to kics_summer_model.h5\n",
      "18/18 [==============================] - 5s 293ms/step - loss: 0.2661 - mean_iou: 0.6563 - dice_coef: 0.8496 - accuracy: 0.8983 - val_loss: 0.3106 - val_mean_iou: 0.6251 - val_dice_coef: 0.8423 - val_accuracy: 0.8880 - lr: 1.4678e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.00014125375446227546.\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2651 - mean_iou: 0.6547 - dice_coef: 0.8539 - accuracy: 0.9035\n",
      "Epoch 62: val_loss did not improve from 0.31058\n",
      "18/18 [==============================] - 3s 192ms/step - loss: 0.2651 - mean_iou: 0.6547 - dice_coef: 0.8539 - accuracy: 0.9035 - val_loss: 0.3202 - val_mean_iou: 0.6242 - val_dice_coef: 0.8424 - val_accuracy: 0.8851 - lr: 1.4125e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.00013593563908785255.\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2462 - mean_iou: 0.6462 - dice_coef: 0.8619 - accuracy: 0.9080\n",
      "Epoch 63: val_loss did not improve from 0.31058\n",
      "18/18 [==============================] - 3s 192ms/step - loss: 0.2462 - mean_iou: 0.6462 - dice_coef: 0.8619 - accuracy: 0.9080 - val_loss: 0.3418 - val_mean_iou: 0.6175 - val_dice_coef: 0.8336 - val_accuracy: 0.8767 - lr: 1.3594e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 0.00013081774742601944.\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2557 - mean_iou: 0.6586 - dice_coef: 0.8568 - accuracy: 0.9026\n",
      "Epoch 64: val_loss improved from 0.31058 to 0.30416, saving model to kics_summer_model.h5\n",
      "18/18 [==============================] - 5s 284ms/step - loss: 0.2557 - mean_iou: 0.6586 - dice_coef: 0.8568 - accuracy: 0.9026 - val_loss: 0.3042 - val_mean_iou: 0.6351 - val_dice_coef: 0.8486 - val_accuracy: 0.8914 - lr: 1.3082e-04\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 0.00012589254117941674.\n",
      "Epoch 65/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 0.2678 - mean_iou: 0.6493 - dice_coef: 0.8512 - accuracy: 0.9020\n",
      "Epoch 65: val_loss did not improve from 0.30416\n",
      "18/18 [==============================] - 3s 189ms/step - loss: 0.2678 - mean_iou: 0.6493 - dice_coef: 0.8512 - accuracy: 0.9020 - val_loss: 0.3114 - val_mean_iou: 0.6269 - val_dice_coef: 0.8470 - val_accuracy: 0.8868 - lr: 1.2589e-04\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 0.00012115276586285887.\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2520 - mean_iou: 0.6472 - dice_coef: 0.8575 - accuracy: 0.9040\n",
      "Epoch 66: val_loss did not improve from 0.30416\n",
      "18/18 [==============================] - 3s 190ms/step - loss: 0.2520 - mean_iou: 0.6472 - dice_coef: 0.8575 - accuracy: 0.9040 - val_loss: 0.3246 - val_mean_iou: 0.6265 - val_dice_coef: 0.8356 - val_accuracy: 0.8835 - lr: 1.2115e-04\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 0.00011659144011798318.\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2591 - mean_iou: 0.6646 - dice_coef: 0.8540 - accuracy: 0.9000\n",
      "Epoch 67: val_loss improved from 0.30416 to 0.29929, saving model to kics_summer_model.h5\n",
      "18/18 [==============================] - 5s 286ms/step - loss: 0.2591 - mean_iou: 0.6646 - dice_coef: 0.8540 - accuracy: 0.9000 - val_loss: 0.2993 - val_mean_iou: 0.6362 - val_dice_coef: 0.8483 - val_accuracy: 0.8908 - lr: 1.1659e-04\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 0.00011220184543019636.\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2567 - mean_iou: 0.6511 - dice_coef: 0.8566 - accuracy: 0.9039\n",
      "Epoch 68: val_loss did not improve from 0.29929\n",
      "18/18 [==============================] - 3s 192ms/step - loss: 0.2567 - mean_iou: 0.6511 - dice_coef: 0.8566 - accuracy: 0.9039 - val_loss: 0.2997 - val_mean_iou: 0.6265 - val_dice_coef: 0.8467 - val_accuracy: 0.8886 - lr: 1.1220e-04\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 0.00010797751623277097.\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2449 - mean_iou: 0.6619 - dice_coef: 0.8636 - accuracy: 0.9081\n",
      "Epoch 69: val_loss did not improve from 0.29929\n",
      "18/18 [==============================] - 3s 188ms/step - loss: 0.2449 - mean_iou: 0.6619 - dice_coef: 0.8636 - accuracy: 0.9081 - val_loss: 0.3092 - val_mean_iou: 0.6278 - val_dice_coef: 0.8428 - val_accuracy: 0.8864 - lr: 1.0798e-04\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 0.00010391223038351694.\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2455 - mean_iou: 0.6610 - dice_coef: 0.8632 - accuracy: 0.9066\n",
      "Epoch 70: val_loss did not improve from 0.29929\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.2455 - mean_iou: 0.6610 - dice_coef: 0.8632 - accuracy: 0.9066 - val_loss: 0.2999 - val_mean_iou: 0.6218 - val_dice_coef: 0.8479 - val_accuracy: 0.8909 - lr: 1.0391e-04\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2466 - mean_iou: 0.6663 - dice_coef: 0.8612 - accuracy: 0.9058\n",
      "Epoch 71: val_loss did not improve from 0.29929\n",
      "18/18 [==============================] - 3s 194ms/step - loss: 0.2466 - mean_iou: 0.6663 - dice_coef: 0.8612 - accuracy: 0.9058 - val_loss: 0.3111 - val_mean_iou: 0.6311 - val_dice_coef: 0.8415 - val_accuracy: 0.8857 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 9.623506263980888e-05.\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2482 - mean_iou: 0.6675 - dice_coef: 0.8613 - accuracy: 0.9075\n",
      "Epoch 72: val_loss did not improve from 0.29929\n",
      "18/18 [==============================] - 3s 197ms/step - loss: 0.2482 - mean_iou: 0.6675 - dice_coef: 0.8613 - accuracy: 0.9075 - val_loss: 0.3007 - val_mean_iou: 0.6370 - val_dice_coef: 0.8496 - val_accuracy: 0.8891 - lr: 9.6235e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 9.261187281287933e-05.\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2378 - mean_iou: 0.6608 - dice_coef: 0.8668 - accuracy: 0.9085\n",
      "Epoch 73: val_loss did not improve from 0.29929\n",
      "18/18 [==============================] - 3s 195ms/step - loss: 0.2378 - mean_iou: 0.6608 - dice_coef: 0.8668 - accuracy: 0.9085 - val_loss: 0.3149 - val_mean_iou: 0.6203 - val_dice_coef: 0.8444 - val_accuracy: 0.8864 - lr: 9.2612e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 8.912509381337455e-05.\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2282 - mean_iou: 0.6592 - dice_coef: 0.8719 - accuracy: 0.9098\n",
      "Epoch 74: val_loss did not improve from 0.29929\n",
      "18/18 [==============================] - 3s 191ms/step - loss: 0.2282 - mean_iou: 0.6592 - dice_coef: 0.8719 - accuracy: 0.9098 - val_loss: 0.3053 - val_mean_iou: 0.6327 - val_dice_coef: 0.8464 - val_accuracy: 0.8876 - lr: 8.9125e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 8.576958985908941e-05.\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2395 - mean_iou: 0.6563 - dice_coef: 0.8666 - accuracy: 0.9092\n",
      "Epoch 75: val_loss improved from 0.29929 to 0.29217, saving model to kics_summer_model.h5\n",
      "18/18 [==============================] - 5s 288ms/step - loss: 0.2395 - mean_iou: 0.6563 - dice_coef: 0.8666 - accuracy: 0.9092 - val_loss: 0.2922 - val_mean_iou: 0.6310 - val_dice_coef: 0.8523 - val_accuracy: 0.8921 - lr: 8.5770e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 8.254041852680186e-05.\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2751 - mean_iou: 0.6561 - dice_coef: 0.8491 - accuracy: 0.8943\n",
      "Epoch 76: val_loss did not improve from 0.29217\n",
      "18/18 [==============================] - 3s 191ms/step - loss: 0.2751 - mean_iou: 0.6561 - dice_coef: 0.8491 - accuracy: 0.8943 - val_loss: 0.3096 - val_mean_iou: 0.6361 - val_dice_coef: 0.8414 - val_accuracy: 0.8861 - lr: 8.2540e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 7.943282347242814e-05.\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2434 - mean_iou: 0.6607 - dice_coef: 0.8659 - accuracy: 0.9078\n",
      "Epoch 77: val_loss did not improve from 0.29217\n",
      "18/18 [==============================] - 3s 189ms/step - loss: 0.2434 - mean_iou: 0.6607 - dice_coef: 0.8659 - accuracy: 0.9078 - val_loss: 0.3129 - val_mean_iou: 0.6289 - val_dice_coef: 0.8494 - val_accuracy: 0.8869 - lr: 7.9433e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 7.644222742526002e-05.\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2250 - mean_iou: 0.6660 - dice_coef: 0.8723 - accuracy: 0.9126\n",
      "Epoch 78: val_loss improved from 0.29217 to 0.28904, saving model to kics_summer_model.h5\n",
      "18/18 [==============================] - 5s 284ms/step - loss: 0.2250 - mean_iou: 0.6660 - dice_coef: 0.8723 - accuracy: 0.9126 - val_loss: 0.2890 - val_mean_iou: 0.6262 - val_dice_coef: 0.8616 - val_accuracy: 0.8953 - lr: 7.6442e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 7.356422544596415e-05.\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2138 - mean_iou: 0.6727 - dice_coef: 0.8763 - accuracy: 0.9163\n",
      "Epoch 79: val_loss did not improve from 0.28904\n",
      "18/18 [==============================] - 3s 194ms/step - loss: 0.2138 - mean_iou: 0.6727 - dice_coef: 0.8763 - accuracy: 0.9163 - val_loss: 0.3014 - val_mean_iou: 0.6371 - val_dice_coef: 0.8475 - val_accuracy: 0.8876 - lr: 7.3564e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 7.079457843841381e-05.\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2352 - mean_iou: 0.6724 - dice_coef: 0.8671 - accuracy: 0.9089\n",
      "Epoch 80: val_loss did not improve from 0.28904\n",
      "18/18 [==============================] - 3s 189ms/step - loss: 0.2352 - mean_iou: 0.6724 - dice_coef: 0.8671 - accuracy: 0.9089 - val_loss: 0.2943 - val_mean_iou: 0.6314 - val_dice_coef: 0.8499 - val_accuracy: 0.8922 - lr: 7.0795e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 6.812920690579612e-05.\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 0.2492 - mean_iou: 0.6494 - dice_coef: 0.8605 - accuracy: 0.9038\n",
      "Epoch 81: val_loss did not improve from 0.28904\n",
      "18/18 [==============================] - 3s 190ms/step - loss: 0.2492 - mean_iou: 0.6494 - dice_coef: 0.8605 - accuracy: 0.9038 - val_loss: 0.2956 - val_mean_iou: 0.6285 - val_dice_coef: 0.8540 - val_accuracy: 0.8911 - lr: 6.8129e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 6.556418494179789e-05.\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2278 - mean_iou: 0.6703 - dice_coef: 0.8702 - accuracy: 0.9125\n",
      "Epoch 82: val_loss improved from 0.28904 to 0.28709, saving model to kics_summer_model.h5\n",
      "18/18 [==============================] - 5s 289ms/step - loss: 0.2278 - mean_iou: 0.6703 - dice_coef: 0.8702 - accuracy: 0.9125 - val_loss: 0.2871 - val_mean_iou: 0.6321 - val_dice_coef: 0.8542 - val_accuracy: 0.8930 - lr: 6.5564e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 6.309573444801933e-05.\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2545 - mean_iou: 0.6601 - dice_coef: 0.8612 - accuracy: 0.9046\n",
      "Epoch 83: val_loss did not improve from 0.28709\n",
      "18/18 [==============================] - 3s 193ms/step - loss: 0.2545 - mean_iou: 0.6601 - dice_coef: 0.8612 - accuracy: 0.9046 - val_loss: 0.3110 - val_mean_iou: 0.6209 - val_dice_coef: 0.8502 - val_accuracy: 0.8881 - lr: 6.3096e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 6.072021956909887e-05.\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2182 - mean_iou: 0.6711 - dice_coef: 0.8757 - accuracy: 0.9174\n",
      "Epoch 84: val_loss did not improve from 0.28709\n",
      "18/18 [==============================] - 3s 192ms/step - loss: 0.2182 - mean_iou: 0.6711 - dice_coef: 0.8757 - accuracy: 0.9174 - val_loss: 0.3055 - val_mean_iou: 0.6272 - val_dice_coef: 0.8519 - val_accuracy: 0.8895 - lr: 6.0720e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 5.843414133735175e-05.\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2274 - mean_iou: 0.6634 - dice_coef: 0.8716 - accuracy: 0.9122\n",
      "Epoch 85: val_loss did not improve from 0.28709\n",
      "18/18 [==============================] - 3s 192ms/step - loss: 0.2274 - mean_iou: 0.6634 - dice_coef: 0.8716 - accuracy: 0.9122 - val_loss: 0.2942 - val_mean_iou: 0.6273 - val_dice_coef: 0.8502 - val_accuracy: 0.8905 - lr: 5.8434e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 5.6234132519034914e-05.\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2356 - mean_iou: 0.6644 - dice_coef: 0.8679 - accuracy: 0.9103\n",
      "Epoch 86: val_loss did not improve from 0.28709\n",
      "18/18 [==============================] - 3s 192ms/step - loss: 0.2356 - mean_iou: 0.6644 - dice_coef: 0.8679 - accuracy: 0.9103 - val_loss: 0.3071 - val_mean_iou: 0.6341 - val_dice_coef: 0.8484 - val_accuracy: 0.8873 - lr: 5.6234e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 5.411695265464638e-05.\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2541 - mean_iou: 0.6687 - dice_coef: 0.8531 - accuracy: 0.9017\n",
      "Epoch 87: val_loss did not improve from 0.28709\n",
      "18/18 [==============================] - 3s 190ms/step - loss: 0.2541 - mean_iou: 0.6687 - dice_coef: 0.8531 - accuracy: 0.9017 - val_loss: 0.2932 - val_mean_iou: 0.6327 - val_dice_coef: 0.8556 - val_accuracy: 0.8932 - lr: 5.4117e-05\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 5.2079483285954625e-05.\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2130 - mean_iou: 0.6672 - dice_coef: 0.8784 - accuracy: 0.9163\n",
      "Epoch 88: val_loss did not improve from 0.28709\n",
      "18/18 [==============================] - 3s 191ms/step - loss: 0.2130 - mean_iou: 0.6672 - dice_coef: 0.8784 - accuracy: 0.9163 - val_loss: 0.3049 - val_mean_iou: 0.6221 - val_dice_coef: 0.8502 - val_accuracy: 0.8886 - lr: 5.2079e-05\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 5.011872336272723e-05.\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2318 - mean_iou: 0.6651 - dice_coef: 0.8700 - accuracy: 0.9106\n",
      "Epoch 89: val_loss did not improve from 0.28709\n",
      "18/18 [==============================] - 3s 189ms/step - loss: 0.2318 - mean_iou: 0.6651 - dice_coef: 0.8700 - accuracy: 0.9106 - val_loss: 0.2921 - val_mean_iou: 0.6371 - val_dice_coef: 0.8540 - val_accuracy: 0.8913 - lr: 5.0119e-05\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 4.823178482239307e-05.\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2350 - mean_iou: 0.6686 - dice_coef: 0.8661 - accuracy: 0.9108\n",
      "Epoch 90: val_loss did not improve from 0.28709\n",
      "18/18 [==============================] - 3s 191ms/step - loss: 0.2350 - mean_iou: 0.6686 - dice_coef: 0.8661 - accuracy: 0.9108 - val_loss: 0.2947 - val_mean_iou: 0.6306 - val_dice_coef: 0.8513 - val_accuracy: 0.8902 - lr: 4.8232e-05\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 4.6415888336127804e-05.\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2032 - mean_iou: 0.6725 - dice_coef: 0.8824 - accuracy: 0.9210\n",
      "Epoch 91: val_loss did not improve from 0.28709\n",
      "18/18 [==============================] - 3s 190ms/step - loss: 0.2032 - mean_iou: 0.6725 - dice_coef: 0.8824 - accuracy: 0.9210 - val_loss: 0.3042 - val_mean_iou: 0.6272 - val_dice_coef: 0.8523 - val_accuracy: 0.8894 - lr: 4.6416e-05\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 4.466835921509631e-05.\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2209 - mean_iou: 0.6742 - dice_coef: 0.8771 - accuracy: 0.9151\n",
      "Epoch 92: val_loss improved from 0.28709 to 0.28127, saving model to kics_summer_model.h5\n",
      "18/18 [==============================] - 5s 283ms/step - loss: 0.2209 - mean_iou: 0.6742 - dice_coef: 0.8771 - accuracy: 0.9151 - val_loss: 0.2813 - val_mean_iou: 0.6465 - val_dice_coef: 0.8574 - val_accuracy: 0.8967 - lr: 4.4668e-05\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 4.298662347082277e-05.\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2310 - mean_iou: 0.6819 - dice_coef: 0.8680 - accuracy: 0.9106\n",
      "Epoch 93: val_loss did not improve from 0.28127\n",
      "18/18 [==============================] - 3s 191ms/step - loss: 0.2310 - mean_iou: 0.6819 - dice_coef: 0.8680 - accuracy: 0.9106 - val_loss: 0.3051 - val_mean_iou: 0.6185 - val_dice_coef: 0.8531 - val_accuracy: 0.8887 - lr: 4.2987e-05\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.1368204023885075e-05.\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2419 - mean_iou: 0.6730 - dice_coef: 0.8632 - accuracy: 0.9070\n",
      "Epoch 94: val_loss did not improve from 0.28127\n",
      "18/18 [==============================] - 3s 190ms/step - loss: 0.2419 - mean_iou: 0.6730 - dice_coef: 0.8632 - accuracy: 0.9070 - val_loss: 0.2992 - val_mean_iou: 0.6318 - val_dice_coef: 0.8519 - val_accuracy: 0.8903 - lr: 4.1368e-05\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 3.9810717055349735e-05.\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2412 - mean_iou: 0.6749 - dice_coef: 0.8644 - accuracy: 0.9073\n",
      "Epoch 95: val_loss did not improve from 0.28127\n",
      "18/18 [==============================] - 3s 190ms/step - loss: 0.2412 - mean_iou: 0.6749 - dice_coef: 0.8644 - accuracy: 0.9073 - val_loss: 0.2917 - val_mean_iou: 0.6329 - val_dice_coef: 0.8561 - val_accuracy: 0.8930 - lr: 3.9811e-05\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.8311868495572876e-05.\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2129 - mean_iou: 0.6872 - dice_coef: 0.8767 - accuracy: 0.9159\n",
      "Epoch 96: val_loss did not improve from 0.28127\n",
      "18/18 [==============================] - 3s 190ms/step - loss: 0.2129 - mean_iou: 0.6872 - dice_coef: 0.8767 - accuracy: 0.9159 - val_loss: 0.2979 - val_mean_iou: 0.6374 - val_dice_coef: 0.8523 - val_accuracy: 0.8912 - lr: 3.8312e-05\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.6869450645195756e-05.\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2023 - mean_iou: 0.6862 - dice_coef: 0.8849 - accuracy: 0.9224\n",
      "Epoch 97: val_loss did not improve from 0.28127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 190ms/step - loss: 0.2023 - mean_iou: 0.6862 - dice_coef: 0.8849 - accuracy: 0.9224 - val_loss: 0.2993 - val_mean_iou: 0.6415 - val_dice_coef: 0.8536 - val_accuracy: 0.8912 - lr: 3.6869e-05\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.5481338923357554e-05.\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2152 - mean_iou: 0.6799 - dice_coef: 0.8772 - accuracy: 0.9185\n",
      "Epoch 98: val_loss did not improve from 0.28127\n",
      "18/18 [==============================] - 3s 188ms/step - loss: 0.2152 - mean_iou: 0.6799 - dice_coef: 0.8772 - accuracy: 0.9185 - val_loss: 0.2867 - val_mean_iou: 0.6343 - val_dice_coef: 0.8626 - val_accuracy: 0.8960 - lr: 3.5481e-05\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 3.414548873833603e-05.\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2371 - mean_iou: 0.6814 - dice_coef: 0.8663 - accuracy: 0.9081\n",
      "Epoch 99: val_loss did not improve from 0.28127\n",
      "18/18 [==============================] - 3s 190ms/step - loss: 0.2371 - mean_iou: 0.6814 - dice_coef: 0.8663 - accuracy: 0.9081 - val_loss: 0.3021 - val_mean_iou: 0.6482 - val_dice_coef: 0.8522 - val_accuracy: 0.8895 - lr: 3.4145e-05\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 3.2859932476006544e-05.\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2294 - mean_iou: 0.6907 - dice_coef: 0.8676 - accuracy: 0.9088\n",
      "Epoch 100: val_loss did not improve from 0.28127\n",
      "18/18 [==============================] - 3s 191ms/step - loss: 0.2294 - mean_iou: 0.6907 - dice_coef: 0.8676 - accuracy: 0.9088 - val_loss: 0.3059 - val_mean_iou: 0.6366 - val_dice_coef: 0.8544 - val_accuracy: 0.8895 - lr: 3.2860e-05\n",
      "\n",
      "Epoch 101: LearningRateScheduler setting learning rate to 3.16227766016838e-05.\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2094 - mean_iou: 0.6972 - dice_coef: 0.8802 - accuracy: 0.9193\n",
      "Epoch 101: val_loss did not improve from 0.28127\n",
      "18/18 [==============================] - 3s 188ms/step - loss: 0.2094 - mean_iou: 0.6972 - dice_coef: 0.8802 - accuracy: 0.9193 - val_loss: 0.2877 - val_mean_iou: 0.6488 - val_dice_coef: 0.8590 - val_accuracy: 0.8954 - lr: 3.1623e-05\n",
      "\n",
      "Epoch 102: LearningRateScheduler setting learning rate to 3.0432198871077225e-05.\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2186 - mean_iou: 0.6973 - dice_coef: 0.8746 - accuracy: 0.9147\n",
      "Epoch 102: val_loss did not improve from 0.28127\n",
      "18/18 [==============================] - 3s 191ms/step - loss: 0.2186 - mean_iou: 0.6973 - dice_coef: 0.8746 - accuracy: 0.9147 - val_loss: 0.2980 - val_mean_iou: 0.6441 - val_dice_coef: 0.8583 - val_accuracy: 0.8933 - lr: 3.0432e-05\n",
      "\n",
      "Epoch 103: LearningRateScheduler setting learning rate to 2.9286445646252364e-05.\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.1952 - mean_iou: 0.7070 - dice_coef: 0.8887 - accuracy: 0.9255\n",
      "Epoch 103: val_loss did not improve from 0.28127\n",
      "18/18 [==============================] - 3s 190ms/step - loss: 0.1952 - mean_iou: 0.7070 - dice_coef: 0.8887 - accuracy: 0.9255 - val_loss: 0.3074 - val_mean_iou: 0.6382 - val_dice_coef: 0.8530 - val_accuracy: 0.8896 - lr: 2.9286e-05\n",
      "\n",
      "Epoch 104: LearningRateScheduler setting learning rate to 2.818382931264454e-05.\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2350 - mean_iou: 0.6961 - dice_coef: 0.8677 - accuracy: 0.9106\n",
      "Epoch 104: val_loss did not improve from 0.28127\n",
      "Restoring model weights from the end of the best epoch: 92.\n",
      "18/18 [==============================] - 3s 196ms/step - loss: 0.2350 - mean_iou: 0.6961 - dice_coef: 0.8677 - accuracy: 0.9106 - val_loss: 0.3009 - val_mean_iou: 0.6459 - val_dice_coef: 0.8552 - val_accuracy: 0.8914 - lr: 2.8184e-05\n",
      "Epoch 104: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    TrainAugmentGenerator(train_images_dir = train_images, train_masks_dir = train_masks, batch_size = batch_size, target_size = image_size), \n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data = ValAugmentGenerator(val_images_dir = val_images, val_masks_dir = val_masks, batch_size = batch_size, target_size = image_size), \n",
    "    validation_steps = validation_steps, \n",
    "    epochs = 200,\n",
    "    callbacks=callbacks,\n",
    "    use_multiprocessing=False,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d2d3f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"./kics_summer_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "752a6bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_gen = ValAugmentGenerator(val_images_dir = test_images, val_masks_dir = test_masks, batch_size = batch_size, target_size = image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a6dbb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 213 images belonging to 1 classes.\n",
      "Found 213 images belonging to 1 classes.\n",
      "50/50 [==============================] - 4s 79ms/step - loss: 0.2964 - mean_iou: 0.6362 - dice_coef: 0.8526 - accuracy: 0.8914\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(\n",
    "    testing_gen,\n",
    "    batch_size = batch_size,\n",
    "    steps=50,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07a32a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss, IoU, dice_coef, test acc: [0.29641783237457275, 0.6362375617027283, 0.8525645732879639, 0.8913767337799072]\n"
     ]
    }
   ],
   "source": [
    "print(\"test loss, IoU, dice_coef, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b90790f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    # 배치에서 이미지와 마스크를 가져옴\n",
    "    batch_img, batch_mask = next(testing_gen)\n",
    "    pred_all = model.predict(batch_img)\n",
    "#     print(\"Predictions Shape:\", np.shape(pred_all))  # (batch_size, height, width, num_classes)\n",
    "\n",
    "    # 예측 마스크 저장\n",
    "    plt.axis('off')\n",
    "    plt.imsave('./예측사진/2%02d_Pmask.png' % i, onehot_to_rgb(pred_all[i], id2code))\n",
    "\n",
    "    # 배치 이미지를 저장할 때, 채널 축 확인\n",
    "    if batch_img.shape[-1] == 3:  # RGB 이미지인 경우\n",
    "        plt.imsave('./예측사진/2%02d_image.png' % i, batch_img[i])  # cmap 제거\n",
    "    elif batch_img.shape[-1] == 1:  # Grayscale 이미지인 경우\n",
    "        plt.imsave('./예측사진/2%02d_image.png' % i, batch_img[i].squeeze(), cmap='gray')\n",
    "\n",
    "    # 정답 마스크 저장\n",
    "    plt.imsave('./예측사진/2%02d_Tmask.png' % i, onehot_to_rgb(batch_mask[i], id2code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd5bfef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
